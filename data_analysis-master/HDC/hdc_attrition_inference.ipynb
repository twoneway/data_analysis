{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from datetime import datetime\n",
    "import shap\n",
    "import json\n",
    "import joblib\n",
    "from pycaret.classification import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'c:\\\\Users\\\\wongi\\\\Desktop\\\\알고리즘랩스\\\\프로젝트\\\\현대산업개발\\\\develop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(f'{path}\\\\algorithmlabs.inference\\\\inference_data_attrition.csv')\n",
    "model = joblib.load(f'{path}\\\\algorithmlabs.inference\\\\pickle_attrition\\\\model.pkl')\n",
    "explainer = joblib.load(f'{path}\\\\algorithmlabs.inference\\\\pickle_attrition\\\\explainer.pkl')\n",
    "encoder_1 = joblib.load(f'{path}\\\\algorithmlabs.inference\\\\pickle_attrition\\\\label_encoder.pkl')\n",
    "encoder_2 = joblib.load(f'{path}\\\\algorithmlabs.inference\\\\pickle_attrition\\\\label_encoder_2.pkl')\n",
    "name_dict = joblib.load(f'{path}\\\\algorithmlabs.inference\\\\pickle_attrition\\\\name_dict.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_data = raw_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_data['YN_HANDICAP'].replace({'Y' : 1, 'N' : 0}, inplace=True)\n",
    "inf_data['YN_SUPPORTED'].replace({'Y' : 1, 'N' : 0}, inplace=True)\n",
    "inf_data['YN_FOREIGNER'].replace({'Y' : 1, 'N' : 0}, inplace=True)\n",
    "inf_data['YN_GENDER'].replace({'M' : 1, 'W' : 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in np.unique(inf_data['DS_BIRTHPLACE']):\n",
    "    if label not in encoder_1.classes_: \n",
    "        encoder_1.classes_ = np.append(encoder_1.classes_, label) \n",
    "inf_data['DS_BIRTHPLACE'] = encoder_1.transform(inf_data['DS_BIRTHPLACE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in np.unique(inf_data['CD_OCCUPATION']):\n",
    "    if label not in encoder_1.classes_: \n",
    "        encoder_1.classes_ = np.append(encoder_1.classes_, label) \n",
    "inf_data['CD_OCCUPATION'] = encoder_1.transform(inf_data['CD_OCCUPATION'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_data.drop([\"ID_SABUN\", \"DS_JOBTYPE\", \"DS_POSITION\", \"DS_DEPT\", \"DS_BONBU\", \"DS_TY_DEPT\", \"DS_OCCUPATION\", \"DS_DUTY\", \n",
    "               \"DS_ADOPTYPE\", \"DS_JOBFAMILY\", \"DS_JOBFAMILY_JOIN\", 'DS_HNAME', 'DS_HANDPHONE', 'DS_EMAIL'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_proba = model.predict_proba(inf_data)[:,1]\n",
    "raw_data['predict_proba'] = predict_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = raw_data[raw_data.columns[0:1].tolist() + raw_data.columns[-1:].tolist() + raw_data.columns[1:-1].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['ID_SABUN', 'predict_proba', 'DS_HNAME', 'DS_POSITION', 'DS_OCCUPATION', 'DS_HANDPHONE', 'DS_EMAIL', \n",
    "           'DS_BONBU', 'DS_DEPT', 'DS_JOBFAMILY', 'DT_BIRTH', 'DS_BIRTHPLACE', 'DT_GROUPJOIN', 'DT_JOIN', 'CD_JOBTYPE',\n",
    "       'CD_POSITION', 'CD_DEPT', 'CD_BONBU', 'TY_DEPT', 'CD_OCCUPATION',\n",
    "       'CD_DUTY', 'CD_ADOPTYPE', 'YN_HANDICAP', 'YN_SUPPORTED', 'YN_FOREIGNER', 'YN_GENDER', 'CD_JOBFAMILY',\n",
    "       'CD_JOBFAMILY_JOIN', 'DS_JOBTYPE', 'DS_TY_DEPT', 'DS_DUTY', 'DS_ADOPTYPE', 'DS_JOBFAMILY_JOIN', \n",
    "       'VAT_THREE_MONTH_AGO', 'VAT_TWO_MONTH_AGO', 'VAT_ONE_MONTH_AGO', 'FINAL_GRADE_RECENT_YEAR', 'WEAK_ONE', 'WEAK_TWO', 'WEAK_THREE',\n",
    "       'WEAK_FOUR', 'WEAK_FIVE', 'WEAK_SIX', 'EDU_CNT']\n",
    "raw_data = raw_data[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.drop([\"CD_JOBTYPE\", \"CD_POSITION\", \"CD_DEPT\", \"CD_BONBU\", \"TY_DEPT\", \"CD_OCCUPATION\", \"CD_DUTY\", \"CD_ADOPTYPE\", \"CD_JOBFAMILY\", \"CD_JOBFAMILY_JOIN\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = explainer.shap_values(inf_data, check_additivity=False)\n",
    "new_shap=[]\n",
    "\n",
    "if len(shap_values) == 2 :\n",
    "    for i in range(len(shap_values[1])) :\n",
    "        new_shap.append(shap_values[1][i]/abs(shap_values[1][i]).sum())\n",
    "else : \n",
    "    for i in range(len(shap_values)) :\n",
    "        new_shap.append(shap_values[i]/abs(shap_values[i]).sum())\n",
    "        \n",
    "feature_weight = pd.DataFrame(new_shap, columns=inf_data.columns)\n",
    "feature_weight['ID_SABUN'] = raw_data['ID_SABUN']\n",
    "feature_weight = feature_weight[feature_weight.columns[-1:].tolist() + feature_weight.columns[:-1].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in raw_data.columns.tolist() : \n",
    "    for name_ex in name_dict.keys() : \n",
    "        if name == name_ex : \n",
    "            raw_data.rename(columns={name : name_dict[name_ex]}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in feature_weight.columns.tolist() : \n",
    "    for name_ex in name_dict.keys() : \n",
    "        if name == name_ex : \n",
    "            feature_weight.rename(columns={name : name_dict[name_ex]}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.to_csv(f'{path}\\\\algorithmlabs.inference\\\\infer_result_attrition.csv', index=False)\n",
    "feature_weight.to_csv(f'{path}\\\\algorithmlabs.inference\\\\feature_weight_attrition.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ahro_",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
