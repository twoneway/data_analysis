{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import joblib\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/ml/algorithmlabs.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = glob.glob(f'{path}/*.csv')\n",
    "name = pd.read_excel('ml/feature_korean_name.xlsx', sheet_name='attrition')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DAAV_BASEINFO_DETAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wongi\\Desktop\\알고리즘랩스\\프로젝트\\현대산업개발\\develop_server\\algorithmlabs.csv\\DAAV_BASEINFO_DETAIL.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_22500\\3824298898.py:2: DtypeWarning: Columns (36,38,39,53,167,171,173) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  bt = pd.read_csv(file_list[4])\n"
     ]
    }
   ],
   "source": [
    "print(file_list[4])\n",
    "bt = pd.read_csv(file_list[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_20296\\1196069732.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bt_data_train['TEMP'] = 'train'\n",
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_20296\\1196069732.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bt_data_test['TEMP'] = 'test'\n"
     ]
    }
   ],
   "source": [
    "# label 세팅 영역으로 21년 1~12월의 재직자 데이터를 참고했을 때, 6개월 후(22년 1~6월)에 누가 퇴사할 위험성이 높은지 예측\n",
    "bt_data_train = bt[(bt['DT_JOIN']<=20221231) & ((bt['DT_RETIRE'] >= 20220101) | (bt['DS_RETIRE'] == '재직'))]\n",
    "bt_data_test = bt[(bt['DT_JOIN']<=20221231) & ((bt['DT_RETIRE'] >= 20230101) | (bt['DS_RETIRE'] == '재직'))]\n",
    "bt_data_train['TEMP'] = 'train'\n",
    "bt_data_test['TEMP'] = 'test'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bt_data = pd.concat([bt_data_train, bt_data_test], axis=0)\n",
    "bt_data = bt_data.reset_index(drop=True)\n",
    "bt_data['DT_YEAR'] = 2022\n",
    "bt_data['ID_SABUN'] = bt_data['ID_SABUN'].astype('str')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt_data = bt_data[[\"TEMP\", \"ID_SABUN\", \"DT_YEAR\", \"DT_GROUPJOIN\", \"DT_JOIN\", \"CD_JOBTYPE\", \"CD_POSITION\", \"CD_DEPT\", \"CD_BONBU\", \"TY_DEPT\", \"DT_RETIRE\", \"DS_RETIRE\", \"CD_OCCUPATION\", \"CD_DUTY\", \n",
    "                   \"DT_BIRTH\", \"DS_BIRTHPLACE\", \"CD_ADOPTYPE\", \"YN_HANDICAP\", \"YN_SUPPORTED\", \"YN_FOREIGNER\", \"YN_GENDER\", \"CD_JOBFAMILY\", \"CD_JOBFAMILY_JOIN\", \n",
    "                   \"DS_JOBTYPE\", \"DS_POSITION\", \"DS_DEPT\", \"DS_BONBU\", \"DS_TY_DEPT\", \"DS_OCCUPATION\", \"DS_DUTY\", \"DS_ADOPTYPE\", \"DS_JOBFAMILY\", \"DS_JOBFAMILY_JOIN\",\n",
    "                   'DS_HNAME', 'DS_HANDPHONE', 'DS_EMAIL']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DACT_USEDVACATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wongi\\Desktop\\알고리즘랩스\\프로젝트\\현대산업개발\\develop_server\\algorithmlabs.csv\\DACT_USEDVACATION.csv\n"
     ]
    }
   ],
   "source": [
    "print(file_list[5])\n",
    "vat = pd.read_csv(file_list[5])\n",
    "vat_data = vat.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vat_data = vat_data[vat_data['YN_COMMONVACATION']!='Y']\n",
    "vat_data.sort_values(by=['ID_SABUN', 'DT_VACAFROM'], ascending=True, inplace=True)\n",
    "vat_data = vat_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vat_list = []\n",
    "\n",
    "for id in vat_data['ID_SABUN'].unique().tolist() : \n",
    "    cnt = 1\n",
    "    temp_vat = vat_data[vat_data['ID_SABUN']==id]\n",
    "    temp_vat = temp_vat.reset_index(drop=True)\n",
    "    for j in range(1, len(temp_vat)) : \n",
    "        first = datetime(int(str(temp_vat['DT_VACAFROM'][j-1])[0:4]), int(str(temp_vat['DT_VACAFROM'][j-1])[4:6]), int(str(temp_vat['DT_VACAFROM'][j-1])[6:8]))\n",
    "        second = datetime(int(str(temp_vat['DT_VACAFROM'][j])[0:4]), int(str(temp_vat['DT_VACAFROM'][j])[4:6]), int(str(temp_vat['DT_VACAFROM'][j])[6:8]))\n",
    "        if (first + timedelta(days=1))==second : \n",
    "            cnt += 1\n",
    "        else : \n",
    "            vat_list.append([id, temp_vat['DT_VACAFROM'][j-1], cnt])\n",
    "            cnt = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vacation = pd.DataFrame(vat_list, columns=['ID_SABUN', 'DT_VACAFROM', 'VAT'])\n",
    "vacation = vacation[vacation['VAT']==1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = []\n",
    "month = []\n",
    "for i in range(len(vacation)) : \n",
    "    year.append(str(vacation['DT_VACAFROM'][i])[0:4])\n",
    "    month.append(str(vacation['DT_VACAFROM'][i])[4:6])\n",
    "    \n",
    "vacation['DT_YEAR'] = year\n",
    "vacation['DT_MONTH'] = month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_list = []\n",
    "\n",
    "for id in vacation['ID_SABUN'].unique().tolist() : \n",
    "    temp_data = vacation[vacation['ID_SABUN']==id]\n",
    "    value_list = temp_data[temp_data['DT_YEAR']=='2022']['DT_MONTH'].value_counts()\n",
    "    for month, cnt in zip (value_list.index, value_list.values) :\n",
    "        date_list.append([id, 2022, month, cnt])\n",
    "        \n",
    "used_data = pd.DataFrame(date_list, columns=['ID_SABUN', 'DT_YEAR', 'DT_MONTH', 'VAT_CNT'])\n",
    "used_data['ID_SABUN'] = used_data['ID_SABUN'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_month = ['04', '05', '06']\n",
    "inf_month = ['10', '11', '12']\n",
    "\n",
    "vat_month = []\n",
    "\n",
    "for i in range(len(bt_data)) : \n",
    "    vat_month_list = [] \n",
    "    if bt_data['TEMP'][i] == 'train' : \n",
    "        temp_data = used_data[used_data['ID_SABUN']==bt_data['ID_SABUN'][i]]\n",
    "        for month in train_month : \n",
    "            if month in temp_data['DT_MONTH'].unique().tolist() : \n",
    "                vat_month_list.append(temp_data[temp_data['DT_MONTH']==month]['VAT_CNT'].values[0])\n",
    "            else : \n",
    "                vat_month_list.append(0)\n",
    "    else : \n",
    "        temp_data = used_data[used_data['ID_SABUN']==bt_data['ID_SABUN'][i]]\n",
    "        for month in inf_month : \n",
    "            if month in temp_data['DT_MONTH'].unique().tolist() : \n",
    "                vat_month_list.append(temp_data[temp_data['DT_MONTH']==month]['VAT_CNT'].values[0])\n",
    "            else : \n",
    "                vat_month_list.append(0)\n",
    "    vat_month.append(vat_month_list)\n",
    "\n",
    "bt_data[['VAT_THREE_MONTH_AGO', 'VAT_TWO_MONTH_AGO', 'VAT_ONE_MONTH_AGO']] = vat_month"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DAJT_FINAL_RESULT, DAKT_MBO_USER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wongi\\Desktop\\알고리즘랩스\\프로젝트\\현대산업개발\\develop_server\\algorithmlabs.csv\\DAJT_FINAL_RESULT.csv\n",
      "c:\\Users\\wongi\\Desktop\\알고리즘랩스\\프로젝트\\현대산업개발\\develop_server\\algorithmlabs.csv\\DAKT_MBO_USER.csv\n"
     ]
    }
   ],
   "source": [
    "print(file_list[8])\n",
    "wpe = pd.read_csv(file_list[8])\n",
    "wpe_data = wpe.copy()\n",
    "wpe_data = wpe_data[(wpe_data['CD_CORP']=='A101') & (wpe_data['DT_YEAR']>=2018)]\n",
    "\n",
    "print(file_list[9])\n",
    "mbo = pd.read_csv(file_list[9])\n",
    "mbo_data = mbo.copy()\n",
    "mbo_data = mbo_data[(mbo_data['CD_CORP']=='A101') & (mbo_data['DT_YEAR']>=2018)]\n",
    "\n",
    "wpe_data = wpe_data[['ID_SABUN', 'DT_YEAR', 'NO_POINT_TOTAL_FIN', 'DS_POINT_TOTAL_FIN']]\n",
    "mbo_data = mbo_data[['CD_USER', 'DT_YEAR', 'NO_FINAL_POINT', 'DS_FINAL_POINT']]\n",
    "mbo_data.rename(columns = {'CD_USER' : 'ID_SABUN'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_data = pd.merge(wpe_data, mbo_data, on=['ID_SABUN', 'DT_YEAR'], how='outer')\n",
    "point_data.dropna(subset = ['NO_POINT_TOTAL_FIN', 'DS_POINT_TOTAL_FIN', 'NO_FINAL_POINT', 'DS_FINAL_POINT'], axis=0, how='all', inplace=True)\n",
    "point_data['ID_SABUN'] = point_data['ID_SABUN'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_years = []\n",
    "\n",
    "for i in range(len(bt_data)) : \n",
    "    temp_list = []\n",
    "    temp_data = point_data[point_data['ID_SABUN']==bt_data['ID_SABUN'][i]]\n",
    "    main = bt_data['DT_YEAR'][i] - 1\n",
    "    if main not in temp_data['DT_YEAR'].unique().tolist() : \n",
    "        temp_list.append(0)\n",
    "        temp_list.append(0)\n",
    "    else : \n",
    "        if ((temp_data[temp_data['DT_YEAR']==main]['NO_POINT_TOTAL_FIN'].values[0]==temp_data[temp_data['DT_YEAR']==main]['NO_POINT_TOTAL_FIN'].values[0]) |\n",
    "        (temp_data[temp_data['DT_YEAR']==main]['DS_POINT_TOTAL_FIN'].values[0]==temp_data[temp_data['DT_YEAR']==main]['DS_POINT_TOTAL_FIN'].values[0])) : \n",
    "            temp_list.append(temp_data[temp_data['DT_YEAR']==main]['NO_POINT_TOTAL_FIN'].values[0])\n",
    "            temp_list.append(temp_data[temp_data['DT_YEAR']==main]['DS_POINT_TOTAL_FIN'].values[0])\n",
    "        else : \n",
    "            temp_list.append(temp_data[temp_data['DT_YEAR']==main]['NO_FINAL_POINT'].values[0])\n",
    "            temp_list.append(temp_data[temp_data['DT_YEAR']==main]['DS_FINAL_POINT'].values[0])  \n",
    "            \n",
    "    one_years.append(temp_list) \n",
    "    \n",
    "bt_data[['FINAL_POINT_RECENT_YEAR', 'FINAL_GRADE_RECENT_YEAR']] = one_years"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DACT_WORK_RESULT_UPDATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wongi\\Desktop\\알고리즘랩스\\프로젝트\\현대산업개발\\develop_server\\algorithmlabs.csv\\DACT_WORK_RESULT_UPDATE.csv\n"
     ]
    }
   ],
   "source": [
    "print(file_list[6])\n",
    "work = pd.read_csv(file_list[6])\n",
    "work_data = work.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = []\n",
    "month = [] \n",
    "for i in range(len(work_data)) : \n",
    "    year.append(int(str(work_data['DT_VACAFROM'][i])[0:4]))\n",
    "    month.append(int(str(work_data['DT_VACAFROM'][i])[4:6]))\n",
    "    \n",
    "work_data['DT_YEAR'] = year\n",
    "work_data['DT_MONTH'] = month\n",
    "work_data['ID_SABUN'] = work_data['ID_SABUN'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_result = [] \n",
    "\n",
    "for i in range(len(bt_data)) : \n",
    "    work_month = [0, 0, 0, 0, 0, 0]\n",
    "    if bt_data['TEMP'][i] == 'train' : \n",
    "        temp_data = work_data[work_data['ID_SABUN']==bt_data['ID_SABUN'][i]]\n",
    "        point_list = temp_data['DT_MONTH'].value_counts()\n",
    "        for point in point_list.index : \n",
    "            if point <= 6 : \n",
    "                work_month[point-1] = point_list[point]\n",
    "    else : \n",
    "        temp_data = work_data[work_data['ID_SABUN']==bt_data['ID_SABUN'][i]]\n",
    "        point_list = temp_data['DT_MONTH'].value_counts()\n",
    "        for point in point_list.index : \n",
    "            if point >= 7 : \n",
    "                work_month[point-7] = point_list[point]\n",
    "            \n",
    "    work_result.append(work_month)\n",
    "    \n",
    "bt_data[['WEAK_ONE', 'WEAK_TWO', 'WEAK_THREE', 'WEAK_FOUR', 'WEAK_FIVE', 'WEAK_SIX']] = work_result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DAET_EDUCATION_REQUEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wongi\\Desktop\\알고리즘랩스\\프로젝트\\현대산업개발\\develop_server\\algorithmlabs.csv\\DAET_EDUCATION_REQUEST.csv\n"
     ]
    }
   ],
   "source": [
    "print(file_list[7])\n",
    "edu = pd.read_csv(file_list[7])\n",
    "edu_data = edu.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "edu_list = []\n",
    "\n",
    "for id in edu_data['ID_SABUN'].unique().tolist() : \n",
    "    first = 0\n",
    "    second = 0\n",
    "    temp_data = edu_data[edu_data['ID_SABUN']==id]\n",
    "    for i in range(len(temp_data)) : \n",
    "        if int(str(temp_data['DT_START'].values[i])[4:6]) in [1, 2, 3, 4, 5, 6] : \n",
    "            first += 1 \n",
    "        else : \n",
    "            second += 1\n",
    "    edu_list.append([id, first, second])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "edu_temp = pd.DataFrame(edu_list, columns=['ID_SABUN', 'FIRST', 'SECOND'])\n",
    "edu_temp['ID_SABUN'] = edu_temp['ID_SABUN'].astype('str')\n",
    "\n",
    "edu_cnt = []\n",
    "for i in range(len(bt_data)) : \n",
    "    if bt_data['ID_SABUN'][i] not in edu_temp['ID_SABUN'].unique().tolist() : \n",
    "        edu_cnt.append(0)\n",
    "    else : \n",
    "        if bt_data['TEMP'][i] == 'train' : \n",
    "            edu_cnt.append(edu_temp[edu_temp['ID_SABUN']==bt_data['ID_SABUN'][i]]['FIRST'].values[0])\n",
    "        else : \n",
    "            edu_cnt.append(edu_temp[edu_temp['ID_SABUN']==bt_data['ID_SABUN'][i]]['SECOND'].values[0])\n",
    "        \n",
    "bt_data['EDU_CNT'] = edu_cnt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_20296\\1326882047.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  missing_data['LABEL'] = label_list\n"
     ]
    }
   ],
   "source": [
    "missing_data = bt_data[bt_data['TEMP']=='train']\n",
    "\n",
    "label_list = []\n",
    "\n",
    "for i in range(len(missing_data)) : \n",
    "    if (missing_data['DS_RETIRE'][i] == '재직') : \n",
    "        label_list.append(0)\n",
    "    else : \n",
    "        if missing_data['DT_RETIRE'][i] > 20220630 and missing_data['DT_RETIRE'][i] < 20230101 : \n",
    "            label_list.append(1)\n",
    "        elif missing_data['DT_RETIRE'][i] >= 20230101 :\n",
    "            label_list.append(0)\n",
    "        else : \n",
    "            label_list.append(-1)\n",
    "    \n",
    "    \n",
    "missing_data['LABEL'] = label_list\n",
    "\n",
    "missing_data = missing_data[missing_data['LABEL']!=-1]\n",
    "missing_data = missing_data[missing_data['DT_JOIN'] <= 20220630]\n",
    "\n",
    "missing_data.drop(['ID_SABUN', 'DT_RETIRE', 'DS_RETIRE', 'FINAL_POINT_RECENT_YEAR', 'TEMP', 'DT_YEAR', \n",
    "                   'DS_JOBTYPE', 'DS_POSITION', 'DS_DEPT', 'DS_BONBU', 'DS_OCCUPATION', 'DS_DUTY', 'DS_ADOPTYPE', 'DS_JOBFAMILY', 'DS_JOBFAMILY_JOIN', 'DS_TY_DEPT',\n",
    "                   'DS_HNAME', 'DS_HANDPHONE', 'DS_EMAIL'], axis=1, inplace=True)\n",
    "missing_rate = (missing_data.isnull().sum()/len(missing_data)).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt_data['CD_JOBTYPE'] = bt_data['CD_JOBTYPE'].fillna(bt_data['CD_JOBTYPE'].mode()[0])\n",
    "bt_data['CD_JOBFAMILY'] = bt_data['CD_JOBFAMILY'].fillna(bt_data['CD_JOBFAMILY'].mode()[0])\n",
    "bt_data['CD_DUTY'] = bt_data['CD_DUTY'].fillna(bt_data['CD_DUTY'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt_data['YN_HANDICAP'] = bt_data['YN_HANDICAP'].fillna('N')\n",
    "bt_data['YN_SUPPORTED'] = bt_data['YN_SUPPORTED'].fillna('N')\n",
    "bt_data['YN_FOREIGNER'] = bt_data['YN_FOREIGNER'].fillna('N')\n",
    "bt_data['YN_GENDER'] = bt_data['YN_GENDER'].fillna('M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ch_grade(data, columns) : \n",
    "    data[columns] = data[columns].replace({'O' : 3, 'R' : 2, 'D' : 1, 0 : 2, 'A' : 3, 'B' : 2, 'C' : 1})\n",
    "    data[columns] = data[columns].fillna(2)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEMP</th>\n",
       "      <th>ID_SABUN</th>\n",
       "      <th>DT_YEAR</th>\n",
       "      <th>DT_GROUPJOIN</th>\n",
       "      <th>DT_JOIN</th>\n",
       "      <th>CD_JOBTYPE</th>\n",
       "      <th>CD_POSITION</th>\n",
       "      <th>CD_DEPT</th>\n",
       "      <th>CD_BONBU</th>\n",
       "      <th>TY_DEPT</th>\n",
       "      <th>...</th>\n",
       "      <th>VAT_ONE_MONTH_AGO</th>\n",
       "      <th>FINAL_POINT_RECENT_YEAR</th>\n",
       "      <th>FINAL_GRADE_RECENT_YEAR</th>\n",
       "      <th>WEAK_ONE</th>\n",
       "      <th>WEAK_TWO</th>\n",
       "      <th>WEAK_THREE</th>\n",
       "      <th>WEAK_FOUR</th>\n",
       "      <th>WEAK_FIVE</th>\n",
       "      <th>WEAK_SIX</th>\n",
       "      <th>EDU_CNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>2731</td>\n",
       "      <td>2022</td>\n",
       "      <td>19880125.0</td>\n",
       "      <td>19880125</td>\n",
       "      <td>45.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>50282364</td>\n",
       "      <td>605</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>70.881</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train</td>\n",
       "      <td>2801</td>\n",
       "      <td>2022</td>\n",
       "      <td>19880704.0</td>\n",
       "      <td>19880704</td>\n",
       "      <td>32.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>50282389</td>\n",
       "      <td>605</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>72.712</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>2837</td>\n",
       "      <td>2022</td>\n",
       "      <td>19881010.0</td>\n",
       "      <td>19881010</td>\n",
       "      <td>45.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>50297026</td>\n",
       "      <td>605</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>71.902</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train</td>\n",
       "      <td>2839</td>\n",
       "      <td>2022</td>\n",
       "      <td>19881010.0</td>\n",
       "      <td>19881010</td>\n",
       "      <td>45.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>50257954</td>\n",
       "      <td>211</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>77.65</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train</td>\n",
       "      <td>2841</td>\n",
       "      <td>2022</td>\n",
       "      <td>19881010.0</td>\n",
       "      <td>19881010</td>\n",
       "      <td>45.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>50282175</td>\n",
       "      <td>605</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>78.245</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2188</th>\n",
       "      <td>test</td>\n",
       "      <td>5207</td>\n",
       "      <td>2022</td>\n",
       "      <td>19990608.0</td>\n",
       "      <td>19990608</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>50301764</td>\n",
       "      <td>211</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2189</th>\n",
       "      <td>test</td>\n",
       "      <td>5727</td>\n",
       "      <td>2022</td>\n",
       "      <td>20051219.0</td>\n",
       "      <td>20051219</td>\n",
       "      <td>49.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>50279104</td>\n",
       "      <td>505</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>96.821</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2190</th>\n",
       "      <td>test</td>\n",
       "      <td>6158</td>\n",
       "      <td>2022</td>\n",
       "      <td>20110701.0</td>\n",
       "      <td>20110701</td>\n",
       "      <td>24.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>50298128</td>\n",
       "      <td>505</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>85.817</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2191</th>\n",
       "      <td>test</td>\n",
       "      <td>6446</td>\n",
       "      <td>2022</td>\n",
       "      <td>19960122.0</td>\n",
       "      <td>20191101</td>\n",
       "      <td>44.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>50063156</td>\n",
       "      <td>605</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2192</th>\n",
       "      <td>test</td>\n",
       "      <td>6686</td>\n",
       "      <td>2022</td>\n",
       "      <td>20221004.0</td>\n",
       "      <td>20221004</td>\n",
       "      <td>36.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>50301730</td>\n",
       "      <td>210</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2193 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       TEMP ID_SABUN  DT_YEAR  DT_GROUPJOIN   DT_JOIN  CD_JOBTYPE  \\\n",
       "0     train     2731     2022    19880125.0  19880125        45.0   \n",
       "1     train     2801     2022    19880704.0  19880704        32.0   \n",
       "2     train     2837     2022    19881010.0  19881010        45.0   \n",
       "3     train     2839     2022    19881010.0  19881010        45.0   \n",
       "4     train     2841     2022    19881010.0  19881010        45.0   \n",
       "...     ...      ...      ...           ...       ...         ...   \n",
       "2188   test     5207     2022    19990608.0  19990608        14.0   \n",
       "2189   test     5727     2022    20051219.0  20051219        49.0   \n",
       "2190   test     6158     2022    20110701.0  20110701        24.0   \n",
       "2191   test     6446     2022    19960122.0  20191101        44.0   \n",
       "2192   test     6686     2022    20221004.0  20221004        36.0   \n",
       "\n",
       "      CD_POSITION   CD_DEPT CD_BONBU  TY_DEPT  ...  VAT_ONE_MONTH_AGO  \\\n",
       "0            12.0  50282364      605      3.0  ...                  0   \n",
       "1            12.0  50282389      605      3.0  ...                  0   \n",
       "2            12.0  50297026      605      3.0  ...                  0   \n",
       "3            12.0  50257954      211      3.0  ...                  0   \n",
       "4            12.0  50282175      605      3.0  ...                  0   \n",
       "...           ...       ...      ...      ...  ...                ...   \n",
       "2188         11.0  50301764      211      1.0  ...                  0   \n",
       "2189         12.0  50279104      505      1.0  ...                  2   \n",
       "2190         13.0  50298128      505      1.0  ...                  1   \n",
       "2191         11.0  50063156      605      1.0  ...                  0   \n",
       "2192         14.0  50301730      210      1.0  ...                  2   \n",
       "\n",
       "     FINAL_POINT_RECENT_YEAR FINAL_GRADE_RECENT_YEAR  WEAK_ONE  WEAK_TWO  \\\n",
       "0                     70.881                       1         0         0   \n",
       "1                     72.712                       1         3         0   \n",
       "2                     71.902                       1         0         0   \n",
       "3                      77.65                       2         0         0   \n",
       "4                     78.245                       2         0         0   \n",
       "...                      ...                     ...       ...       ...   \n",
       "2188                     NaN                       3         0         0   \n",
       "2189                  96.821                       3         0         0   \n",
       "2190                  85.817                       2         0         1   \n",
       "2191                     NaN                       2         0         0   \n",
       "2192                     0.0                       2         0         0   \n",
       "\n",
       "     WEAK_THREE  WEAK_FOUR WEAK_FIVE WEAK_SIX EDU_CNT  \n",
       "0             0          0         0        0       0  \n",
       "1             0          0         0        0       1  \n",
       "2             0          0         0        0       0  \n",
       "3             0          0         0        0       0  \n",
       "4             0          0         0        0       0  \n",
       "...         ...        ...       ...      ...     ...  \n",
       "2188          0          0         0        0       0  \n",
       "2189          0          0         0        0       0  \n",
       "2190          0          0         0        0       0  \n",
       "2191          0          0         0        0       0  \n",
       "2192          0          0         0        0       0  \n",
       "\n",
       "[2193 rows x 48 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch_grade(bt_data, 'FINAL_GRADE_RECENT_YEAR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "birth_change = {' ' : '서울', '대한민국' : '서울', '충청남도' : '충남', '광주광역시' : '광주', ' 서울' : '서울', '강원도' : '강원', '상주' : '경북', '구미' : '경북',\n",
    "                '충남 서산' : '충남', '경기도 성남시' : '경기', '수원' : '경기', '한국' : '서울', '파라과이' : '해외', '대한민국' : '서울', '전북 익산' : '전북', \n",
    "                '강릉' : '강원', '경북 대구' : '대구', '포항' : '경북', '청주' : '충북', '경기도 안양시' : '경기', '부산광역시' : '부산', '전북 전주' : '전북',\n",
    "                '전남 광주' : '광주', '경남 통영시' : '경남', '경상남도' : '경남', '경기도 수원시' : '경기', '경기 광명' : '경기', '강원도 홍천' : '강원',\n",
    "                '경북 영덕군' : '경북', ' 충주 ' : '충북', '경기도 수원' : '경기', '인천광역시' : '인천', '서울특별시' : '서울', '전북 남원' : '전북'}\n",
    "\n",
    "bt_data['DS_BIRTHPLACE'].replace(birth_change, inplace=True)\n",
    "bt_data['DS_BIRTHPLACE'] = bt_data['DS_BIRTHPLACE'].fillna(bt_data['DS_BIRTHPLACE'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = bt_data[bt_data['TEMP']=='train']\n",
    "inference_data = bt_data[bt_data['TEMP']=='test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_20296\\2033796102.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data['LABEL'] = label_list\n"
     ]
    }
   ],
   "source": [
    "# feature : 20220630 / label : 20230101 / v4\n",
    "# feature : 20220630 / label : 20221001 / v5\n",
    "# feature : 20220331 / label : 20220630 / v6\n",
    "# feature : 20220930 / label : 20230101 / v7\n",
    "\n",
    "label_list = []\n",
    "\n",
    "for i in range(len(train_data)) : \n",
    "    if (train_data['DS_RETIRE'][i] == '재직') : \n",
    "        label_list.append(0)\n",
    "    else : \n",
    "        if train_data['DT_RETIRE'][i] > 20220630 and train_data['DT_RETIRE'][i] < 20230101 : \n",
    "            label_list.append(1)\n",
    "        elif train_data['DT_RETIRE'][i] >= 20230101 :\n",
    "            label_list.append(0)\n",
    "        else : \n",
    "            label_list.append(-1)\n",
    "    \n",
    "    \n",
    "train_data['LABEL'] = label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data[train_data['LABEL']!=-1]\n",
    "train_data = train_data[train_data['DT_JOIN'] <= 20220630]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_20296\\2148771533.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  inference_data.drop(['DT_RETIRE', 'DS_RETIRE', 'FINAL_POINT_RECENT_YEAR', 'TEMP', 'DT_YEAR'], axis=1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "train_data.drop(['DT_RETIRE', 'DS_RETIRE', 'FINAL_POINT_RECENT_YEAR', 'TEMP', 'DT_YEAR', 'DS_HNAME', 'DS_HANDPHONE', 'DS_EMAIL'], axis=1, inplace=True)\n",
    "inference_data.drop(['DT_RETIRE', 'DS_RETIRE', 'FINAL_POINT_RECENT_YEAR', 'TEMP', 'DT_YEAR'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_dict = {}\n",
    "for i in range(len(name)) : \n",
    "    name_dict[name['feature'][i]] = name['feature_name'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c:\\\\Users\\\\wongi\\\\Desktop\\\\알고리즘랩스\\\\프로젝트\\\\현대산업개발\\\\develop\\\\algorithmlabs.inference\\\\pickle_attrition\\\\name_dict.pkl']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today = datetime.today().strftime(\"%Y%m%d\")\n",
    "Path(f\"/ml/algorithmlabs.inference/{today}/attrition/pickle\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "train_data.to_csv(f\"/ml/algorithmlabs.inference/{today}/attrition/train_data_attrition.csv\", index=False)\n",
    "inference_data.to_csv(f\"/ml/algorithmlabs.inference/{today}/attrition/inference_data_attrition.csv\", index=False)\n",
    "joblib.dump(missing_rate, f\"/ml/algorithmlabs.inference/{today}/attrition/pickle/missing_rate.pkl\")\n",
    "joblib.dump(name_dict, f\"/ml/algorithmlabs.inference/{today}/attrition/pickle/name_dict.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "practice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "055ce310dfd61a9649730d91fa4dbaceeaf5df2d807db0aa8f4c64267c1c77f9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
