{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 사용한 패키지 목록 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import accuracy\n",
    "from surprise import KNNBasic\n",
    "from surprise.model_selection import LeaveOneOut\n",
    "from reco_utils.common.general_utils import invert_dictionary \n",
    "#trainset을 DataFrame으로 확인하는 패키지\n",
    "# 설치 방법 : pip install pre-reco-utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 로컬에서 데이터셋 업로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrd_raw = pd.read_csv(r'C:\\user_group_list.csv')\n",
    "hrd_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Surprise 패키지 형식에 맞도록 데이터셋 업로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(1, 5)) #rating_scale은 1~5점 척도\n",
    "hrd_data = Dataset.load_from_df(hrd_raw[['User_ID', 'Item_ID', 'Rating']], reader) \n",
    "# user,item, rating 순으로 rating 점수가 5점척도의 데이터셋 형태로 surprise 패키지가 읽음 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 사용할 알고리즘 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_options = {'name' : 'pearson', 'user_based' : False} # 사용하는 유사도 측정방식 : 피어슨, 아이템 기반 협력필터링 사용 \n",
    "algo = KNNBasic(sim_options=sim_options) # KNNBasic 알고리즘 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 데이터셋 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = LeaveOneOut(n_splits=5, random_state=1, min_n_ratings=1)\n",
    "# LeaveOneOut : testset에 반드시 각각의 user들의 점수가 1개 포함되도록 하는 함수 \n",
    "# n_splits : 5개의 fold로 나누기\n",
    "# min_n_ratings = 1 : trainset에 반드시 최소 1개 이상 user의 rating 점수가 포함되어야 한다라는 조건"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for trainset, testset in kf.split(hrd_data):\n",
    "    \n",
    "    # train and test algorithm\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "\n",
    "    # Compute and print Root Mean Squared Error\n",
    "    accuracy.rmse(predictions, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5-1. 분할된 데이터셋 시각화(나누어진 데이터셋을 표로 시각화하여 보는 것이기에 필요성은 떨어짐)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def surprise_trainset_to_df(trainset, col_user=\"uid\", col_item=\"iid\", col_rating=\"rating\"): \n",
    "    df = pd.DataFrame(trainset.all_ratings(), columns=[col_user, col_item, col_rating])\n",
    "    map_user = trainset._inner2raw_id_users if trainset._inner2raw_id_users is not None else invert_dictionary(trainset._raw2inner_id_users)\n",
    "    map_item = trainset._inner2raw_id_items if trainset._inner2raw_id_items is not None else invert_dictionary(trainset._raw2inner_id_items)\n",
    "    df[col_user] = df[col_user].map(map_user)\n",
    "    df[col_item] = df[col_item].map(map_item)\n",
    "    return df\n",
    "# Surprise 패키지는 분석 시 raw_data -> inner_data로 변환하여 분석(surprise에 더 적합한 데이터 형식으로 변경)\n",
    "# 따라서 직접 trainset을 visualize할 수 없어 이를 다시 raw_data로 변경하는 가공과정이 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surprise_trainset_to_df(trainset, col_user=\"uid\", col_item=\"iid\", col_rating=\"rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_frame = pd.DataFrame(testset, columns=['uid', 'iid', 'rating'])\n",
    "test_frame\n",
    "# testset은 반환형식이 list라 별도의 변환없이 접근 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. 추천 리스트 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_number = 10003 # User_ID 입력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6-1. user가 과거 학습했던 item 리스트 출력 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seen_item = hrd_raw.loc[hrd_raw['User_ID']==id_number, ['Item_ID', 'Rating'], ] #학습했었던 item 목록 저장\n",
    "experience = pd.DataFrame(seen_item)\n",
    "experience.sort_values([\"Rating\"], ascending=[False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6-2. user가 학습하지 않았던 item 중에서 추천 리스트 출력  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unique_ids = hrd_raw['Item_ID'].unique() # item의 unqiue value 저장\n",
    "already_seen = hrd_raw.loc[hrd_raw['User_ID']==id_number, 'Item_ID'] # id_number에 해당하는 user의 학습했었던 item 목록 저장\n",
    "hrd_to_predict = np.setdiff1d(unique_ids,already_seen) # 전체 unique value에서 학습한 아이템 목록 제외\n",
    "my_recs = []\n",
    "for iid in hrd_to_predict:\n",
    "    my_recs.append((iid, algo.predict(uid=id_number, iid=iid).est)) \n",
    "    # 예측을 진행한 후 인접한 이웃이 충분히 존재하지 않을 경우 predictions 값을 전체 평점의 평균을 출력하도록 설정되어 해당사항 유의\n",
    "    \n",
    "pd.DataFrame(my_recs, columns=['iid', 'predictions']).sort_values('predictions', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_excel = pd.DataFrame(my_recs, columns=['iid', 'predictions']).sort_values('predictions', ascending=False).head(10)\n",
    "# data_to_excel.to_excel(excel_writer='sample.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. 추천 리스트 필터링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "조건 1. user와 동일한 조직(사업부, 실) 기준으로 20% 이상 학습한 과목에 대한 필터링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7-1. 데이터 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_data = hrd_raw.loc[hrd_raw['User_ID']==id_number, ['사업부', '실', '조직_담당', '직무명']] #user의 사업부, 실 정보 행에서 읽어오기\n",
    "group_center = group_data['사업부'].values[0] # '사업부' 이름 저장\n",
    "group_room = group_data['실'].values[0] # '실' 이름 저장\n",
    "group_organization = group_data['조직_담당'].values[0]\n",
    "group_job = group_data['직무명'].values[0]\n",
    "print(group_center, group_room, group_organization, group_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# group_list = hrd_raw.loc[hrd_raw['사업부']==group_center, 'Item_ID'] # user의 '사업부'를 기준으로 해당 과목 읽어오기\n",
    "group_list = hrd_raw.loc[hrd_raw['실']==group_room, 'Item_ID'] # user의 '실'을 기준으로 해당 과목 읽어오기\n",
    "# group_list = hrd_raw.loc[hrd_raw['조직_담당']==group_organization, 'Item_ID'] # user의 '실'을 기준으로 해당 과목 읽어오기\n",
    "# group_list = hrd_raw.loc[hrd_raw['직무명']==group_job, 'Item_ID'] # user의 '실'을 기준으로 해당 과목 읽어오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7-2. 데이터 타입 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_list = group_list.value_counts(normalize=True) # '실' 기준 과목명에서 각각의 과목들 상대적 비율 출력하기 \n",
    "ratio_list_frame = ratio_list.reset_index(name= 'count') # Series -> DataFrame으로 변경\n",
    "ratio_list_frame.columns = ['Item_ID', 'Ratio'] # DataFrame Column명 정리\n",
    "ratio_list_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7-3. 20% 기준으로 데이터 분할하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtering_list = ratio_list_frame.loc[ratio_list_frame['Ratio'] < 0.2, 'Item_ID'] # 20%이하는 포함하지 않도록 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7-4. 공통과목 포함시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_raw = pd.read_csv(r'C:\\common list.csv') # 공통과목 리스트 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_raw_series = np.array(common_raw['Item_List'].tolist()) # DataFrame -> Series\n",
    "common_list = pd.Series(common_raw_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_filtering = list(filtering_list)  # Series -> List 반복문에 원활하게 사용하기 위해 변경\n",
    "list_common = list(common_list) # Series -> List\n",
    "for i in list_filtering :\n",
    "    for j in list_common : \n",
    "        if i == j :\n",
    "            list_filtering.remove(i) # 공통과정을 filtering_list 목록에서 미리 제거하여 포함되지 않도록 하기\n",
    "            break\n",
    "        else : \n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hrd_to_filtering_predict = np.setdiff1d(hrd_to_predict,filtering_list) \n",
    "# 기존의 추천 리스트에서 필터링 과목 제거 \n",
    "# hrd_to_predict(기학습했던 과목 제외한 모든 과목) - \n",
    "# filtering_list(특정 부서 기준으로 20%인 이하인 과목 제거)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7-5. 필터링된 추천 리스트 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = []\n",
    "for iid in hrd_to_filtering_predict:\n",
    "    my_list.append((iid, algo.predict(uid=id_number, iid=iid).est)) \n",
    "    \n",
    "pd.DataFrame(my_list, columns=['iid', 'predictions']).sort_values('predictions', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratio_list_frame.to_excel(excel_writer='sample.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
