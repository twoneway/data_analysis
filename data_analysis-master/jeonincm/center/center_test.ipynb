{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUz-ZH00eE2v",
        "outputId": "fe06284c-f878-475e-8fcd-e7e9cb4510ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shap"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0SPyWBzerIg",
        "outputId": "1a6f5cba-9c90-47da-96ae-8d02d7a68447"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting shap\n",
            "  Downloading shap-0.41.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (569 kB)\n",
            "\u001b[K     |████████████████████████████████| 569 kB 8.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>20.9 in /usr/local/lib/python3.7/dist-packages (from shap) (21.3)\n",
            "Collecting slicer==0.0.7\n",
            "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from shap) (0.56.2)\n",
            "Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.7/dist-packages (from shap) (4.64.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from shap) (1.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from shap) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from shap) (1.7.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from shap) (1.3.5)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from shap) (1.5.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>20.9->shap) (3.0.9)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.7/dist-packages (from numba->shap) (0.39.1)\n",
            "Requirement already satisfied: setuptools<60 in /usr/local/lib/python3.7/dist-packages (from numba->shap) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from numba->shap) (5.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->numba->shap) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->numba->shap) (3.8.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->shap) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->shap) (2022.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->shap) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->shap) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->shap) (3.1.0)\n",
            "Installing collected packages: slicer, shap\n",
            "Successfully installed shap-0.41.0 slicer-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install -y fonts-nanum\n",
        "!sudo fc-cache -fv\n",
        "!rm ~/.cache/matplotlib -rf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CiETsGq4esuK",
        "outputId": "9bd868a8-e726-417f-c360-156ea00967ae"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  fonts-nanum\n",
            "0 upgraded, 1 newly installed, 0 to remove and 12 not upgraded.\n",
            "Need to get 9,604 kB of archives.\n",
            "After this operation, 29.5 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-nanum all 20170925-1 [9,604 kB]\n",
            "Fetched 9,604 kB in 1s (9,277 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package fonts-nanum.\n",
            "(Reading database ... 123934 files and directories currently installed.)\n",
            "Preparing to unpack .../fonts-nanum_20170925-1_all.deb ...\n",
            "Unpacking fonts-nanum (20170925-1) ...\n",
            "Setting up fonts-nanum (20170925-1) ...\n",
            "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n",
            "/usr/share/fonts: caching, new cache contents: 0 fonts, 1 dirs\n",
            "/usr/share/fonts/truetype: caching, new cache contents: 0 fonts, 3 dirs\n",
            "/usr/share/fonts/truetype/humor-sans: caching, new cache contents: 1 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/liberation: caching, new cache contents: 16 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/nanum: caching, new cache contents: 10 fonts, 0 dirs\n",
            "/usr/local/share/fonts: caching, new cache contents: 0 fonts, 0 dirs\n",
            "/root/.local/share/fonts: skipping, no such directory\n",
            "/root/.fonts: skipping, no such directory\n",
            "/var/cache/fontconfig: cleaning cache directory\n",
            "/root/.cache/fontconfig: not cleaning non-existent cache directory\n",
            "/root/.fontconfig: not cleaning non-existent cache directory\n",
            "fc-cache: succeeded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error, r2_score\n",
        "from imblearn.pipeline import Pipeline\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import shap\n",
        "from datetime import datetime\n",
        "import json\n",
        "import joblib"
      ],
      "metadata": {
        "id": "FNltzNpeet8H"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rc('font', family='NanumBarunGothic')"
      ],
      "metadata": {
        "id": "uJy-mHJmezB8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.options.display.float_format = '{:.6f}'.format"
      ],
      "metadata": {
        "id": "yr62Uu7ce2Zi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sheetname = '물류센터'"
      ],
      "metadata": {
        "id": "kBFkiULE7yRM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pre_data = pd.read_excel('/content/drive/MyDrive/Colab Notebooks/전인CM/input/전인CM_Inference.xlsx', sheet_name=sheetname, engine='openpyxl')"
      ],
      "metadata": {
        "id": "7gnJt-2Ora5Z"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pre_data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHUlYOBgsKmH",
        "outputId": "3ec1b2e8-a233-4de5-f2af-f6ff67f2791d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1 entries, 0 to 0\n",
            "Data columns (total 17 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   착공년도        1 non-null      int64  \n",
            " 1   프로젝트명       1 non-null      object \n",
            " 2   연면적(평)      1 non-null      int64  \n",
            " 3   지하층         1 non-null      int64  \n",
            " 4   지상층         1 non-null      int64  \n",
            " 5   층           1 non-null      int64  \n",
            " 6   지형          1 non-null      object \n",
            " 7   공법          1 non-null      object \n",
            " 8   상온          1 non-null      float64\n",
            " 9   저온          1 non-null      float64\n",
            " 10  기타          1 non-null      float64\n",
            " 11  시공사 등급      1 non-null      int64  \n",
            " 12  공사기간(개월)    1 non-null      int64  \n",
            " 13  공사비지수       1 non-null      float64\n",
            " 14  지역          1 non-null      object \n",
            " 15  건물외형        1 non-null      object \n",
            " 16  철거공사 포함 여부  1 non-null      object \n",
            "dtypes: float64(4), int64(7), object(6)\n",
            "memory usage: 264.0+ bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label = pre_data.copy()"
      ],
      "metadata": {
        "id": "0LGHvfUPzEJt"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "end_model = joblib.load('/content/drive/My Drive/Colab Notebooks/전인CM/output/물류센터_model.pkl')\n",
        "scaler = joblib.load('/content/drive/My Drive/Colab Notebooks/전인CM/output/물류센터_scaler.pkl')\n",
        "con_data = joblib.load('/content/drive/My Drive/Colab Notebooks/전인CM/output/물류센터_data.pkl')\n",
        "en_data = joblib.load('/content/drive/My Drive/Colab Notebooks/전인CM/output/물류센터_en_data.pkl')\n",
        "explainer = joblib.load('/content/drive/My Drive/Colab Notebooks/전인CM/output/물류센터_explainer.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47PF4gTb7JEp",
        "outputId": "756ce391-8fa4-4250-dd70-52a8101ce61b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[01:01:18] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[01:01:20] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 결측치 처리\n",
        "nalist = ['공법', '상온', '저온', '기타','시공사 등급'] # 등급 : 최빈값으로 처리해야함\n",
        "\n",
        "for col in nalist : # 최빈 처리 \n",
        "  if (pre_data[col].dtype == object) or (col == '시공사 등급') :\n",
        "    pre_data.loc[pre_data[col].isna()==True,col] = con_data[col].mode()[0]\n",
        "  else :\n",
        "    pre_data.loc[pre_data[col].isna()==True,col] = con_data[col].mean()"
      ],
      "metadata": {
        "id": "JhCis1RKsjEf"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# label encoding\n",
        "pre_data['건물외형'] = pre_data['건물외형'].replace('정형', 0)\n",
        "pre_data['건물외형'] = pre_data['건물외형'].replace('비정형', 1)\n",
        "pre_data['철거공사 포함 여부'] = pre_data['철거공사 포함 여부'].replace('미포함', 0)\n",
        "pre_data['철거공사 포함 여부'] = pre_data['철거공사 포함 여부'].replace('포함', 1)\n",
        "\n",
        "sector = []\n",
        "for i in range(len(pre_data)) :\n",
        "  if pre_data['지역'][i] == '서울' : \n",
        "    sector.append(1)\n",
        "  elif pre_data['지역'][i] == '인천' : \n",
        "    sector.append(2)\n",
        "  elif pre_data['지역'][i] == '경기' : \n",
        "    sector.append(3)\n",
        "  elif pre_data['지역'][i] == '충청' : \n",
        "    sector.append(4)\n",
        "  elif pre_data['지역'][i] == '강원' : \n",
        "    sector.append(5)\n",
        "  elif pre_data['지역'][i] == '영남' : \n",
        "    sector.append(6)\n",
        "  elif pre_data['지역'][i] == '호남' : \n",
        "    sector.append(7)\n",
        "\n",
        "pre_data['지역'] =  sector"
      ],
      "metadata": {
        "id": "PFTF_ezj3so6"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pre_data.loc[pre_data.공법 == 'RC / PC', '공법'] = 'PC / RC'"
      ],
      "metadata": {
        "id": "0-qpKPA6TXCE"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sec = pre_data.copy()\n",
        "\n",
        "one_hot = ['공법_PC / PEB', '공법_PC / 철골조', '공법_RC', '공법_SC / RC / PEB', '공법_SRC', '공법_SRC / PEB', '지형_평지', '공법_PC / RC', '공법_PC / RC / 철골조', '공법_PC / SRC']\n",
        "for col in one_hot  :\n",
        "  sec[col] = 0\n",
        "if sec['지형'][0] == '평지' : \n",
        "  sec['지형_평지'] = 1\n",
        "\n",
        "if '공법_'+sec['공법'][0] in one_hot : \n",
        "  sec['공법_'+sec['공법'][0]] = 1\n",
        "\n",
        "sec = sec[['착공년도', '프로젝트명', '연면적(평)', '지하층', '지상층', '층', '상온', '저온', '기타',\n",
        "       '시공사 등급', '공사기간(개월)', '공사비지수', '지역', '건물외형', '철거공사 포함 여부', '지형_평지',\n",
        "       '공법_PC / PEB', '공법_PC / RC', '공법_PC / RC / 철골조', '공법_PC / 철골조', '공법_RC',\n",
        "       '공법_SC / RC / PEB', '공법_SRC', '공법_SRC / PEB', '공법_PC / SRC']]"
      ],
      "metadata": {
        "id": "EsTn-VUvvVXO"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main = pd.concat([con_data, sec], axis=0).reset_index(drop=True)\n",
        "\n",
        "temp = sec.drop(['프로젝트명'], axis=1)\n",
        "scaled_temp = scaler.transform(temp)\n",
        "sec_data = pd.DataFrame(data = scaled_temp, index=temp.index, columns=temp.columns)\n",
        "conc = pd.concat([en_data, sec_data], axis=0).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "7VK0vqCdMQJp"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pre_list = sec['프로젝트명']\n",
        "pred_sec = pd.DataFrame(columns=pre_list)"
      ],
      "metadata": {
        "id": "7ce_MgNPPDhp"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 유사도 측정 로직 수정\n",
        "for name in pre_list : \n",
        "  data_list = []\n",
        "  main_index = main[main['프로젝트명']==name].index\n",
        "  main_values = conc.values[main_index]\n",
        "  main_year = conc['착공년도'][main_index].values[0]\n",
        "\n",
        "  for num in range(len(conc)) : \n",
        "    compare_values = conc.values[num]\n",
        "    uclid_dist = np.sqrt(np.sum(np.square(main_values-compare_values)))\n",
        "    if (main_year==conc['착공년도'].min()) : \n",
        "      data_list.append(uclid_dist)\n",
        "    else : \n",
        "      if (main_year < conc['착공년도'][num]) :\n",
        "        data_list.append(0)\n",
        "      else : \n",
        "        data_list.append(uclid_dist)\n",
        "  pred_sec[name] = data_list"
      ],
      "metadata": {
        "id": "ETZGAx2Di-Jp"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sim = pred_sec[:len(con_data)]\n",
        "\n",
        "pred_sim = []\n",
        "for name in pre_data['프로젝트명'] : \n",
        "  unique_data = train_sim[name].unique()\n",
        "  zero = [0]\n",
        "  sim_data = np.setdiff1d(unique_data, zero).min()\n",
        "  pred_sim.append(sim_data)"
      ],
      "metadata": {
        "id": "W1AqgNe4QGqM"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similar_cons = ['토목', '건축', '설비', '전기', '통신', '소방', '조경', '추가공종', '간접비 및 이윤']"
      ],
      "metadata": {
        "id": "2Blp4TOzN9sS"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similar_fe = ['착공년도', '프로젝트명', '연면적(평)', '지하층', '지상층', '층', '지형', '공법', '상온', '저온',\n",
        "       '기타', '시공사 등급', '공사기간(개월)', '공사비', '공사비지수', '지역', '건물외형', '철거공사 포함 여부']"
      ],
      "metadata": {
        "id": "ZFgrFz8i-5_-"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_result_1 = [] \n",
        "i = 0\n",
        "for name in pre_list : \n",
        "  pred_result_1.append(con_data.loc[pred_sec[name]==pred_sim[i]]['2015 기준공사비'].values[0])\n",
        "  i += 1"
      ],
      "metadata": {
        "id": "rbCnfswCUcel"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 가장 유사도가 깊은 공사의 공종 데이터 가져오기 \n",
        "pred_result_2 = []\n",
        "i = 0\n",
        "for name in pre_data['프로젝트명'] : \n",
        "  sim_values = []\n",
        "  for project in similar_cons : \n",
        "    sim_values.append(con_data.loc[pred_sec[name]== pred_sim[i]][project].values[0])\n",
        "  pred_result_2.append(sim_values)\n",
        "  i += 1"
      ],
      "metadata": {
        "id": "L0ljLy6YY5R6"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_result_3 = []\n",
        "i = 0\n",
        "for name in pre_data['프로젝트명'] : \n",
        "  sim_values = []\n",
        "  for project in similar_fe : \n",
        "    sim_values.append(con_data.loc[pred_sec[name]== pred_sim[i]][project].values[0])\n",
        "  pred_result_3.append(sim_values)\n",
        "  i += 1"
      ],
      "metadata": {
        "id": "ZzeR_dP5nkka"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pre_data['유사도 기준공사비'] = pred_result_1\n",
        "pre_data[['토목', '건축', '설비', '전기', '통신', '소방', '조경', '추가공종', '간접비 및 이윤']] = pred_result_2"
      ],
      "metadata": {
        "id": "OTZPeoPRZmqe"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similar_data = pd.DataFrame(pred_result_3, columns = similar_fe)\n",
        "similar_data['지역'] = label['지역']\n",
        "similar_data['건물외형'] = label['건물외형']\n",
        "similar_data['철거공사 포함 여부'] = label['철거공사 포함 여부']\n",
        "similar_data['유사도'] = (1-pred_sim[0]/10)*100"
      ],
      "metadata": {
        "id": "dALlDooLTL03"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similar_data.to_csv('/content/drive/My Drive/Colab Notebooks/전인CM/output/similarity_물류센터.csv', encoding='utf-8-sig', index=False)"
      ],
      "metadata": {
        "id": "vk_7FtT_FZY1"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "inference 모델링"
      ],
      "metadata": {
        "id": "aY_ajXYWlzMT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fe_data = pre_data.copy()\n",
        "\n",
        "one_hot = ['공법_PC / PEB', '공법_PC / 철골조', '공법_RC', '공법_SC / RC / PEB', '공법_SRC', '공법_SRC / PEB', '지형_평지', '공법_PC / RC', '공법_PC / RC / 철골조', '공법_PC / SRC']\n",
        "for col in one_hot  :\n",
        "  fe_data[col] = 0\n",
        "if fe_data['지형'][0] == '평지' : \n",
        "  fe_data['지형_평지'] = 1\n",
        "\n",
        "if '공법_'+fe_data['공법'][0] in one_hot : \n",
        "  fe_data['공법_'+fe_data['공법'][0]] = 1\n",
        "\n",
        "fe_data = fe_data[['착공년도', '연면적(평)', '지하층', '지상층', '층', '상온', '저온', '기타', '시공사 등급',\n",
        "       '공사기간(개월)', '공사비지수', '토목', '건축', '설비', '전기', '통신', '소방', '조경', '추가공종',\n",
        "       '간접비 및 이윤', '지역', '건물외형', '철거공사 포함 여부', '유사도 기준공사비', '지형_평지',\n",
        "       '공법_PC / PEB', '공법_PC / RC', '공법_PC / RC / 철골조', '공법_PC / 철골조', '공법_RC',\n",
        "       '공법_SC / RC / PEB', '공법_SRC', '공법_SRC / PEB', '공법_PC / SRC']]"
      ],
      "metadata": {
        "id": "HQ6HXHllWoHH"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pred_data = end_model.predict(fe_data)\n",
        "pred_data = end_model.predict(fe_data)\n",
        "pre_data['예측 총공사비'] = pred_data[0]*pre_data['공사비지수'][0]/100\n",
        "pre_data['예측 평당가'] = pred_data[0]*pre_data['공사비지수'][0]/100/pre_data['연면적(평)'][0]"
      ],
      "metadata": {
        "id": "0yC4LXRgcvkd"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pre_data['지역'] = label['지역']\n",
        "pre_data['건물외형'] = label['건물외형']\n",
        "pre_data['철거공사 포함 여부'] = label['철거공사 포함 여부']"
      ],
      "metadata": {
        "id": "Vm1uzNYnl3zN"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pre_data.to_csv('/content/drive/My Drive/Colab Notebooks/전인CM/output/output_물류센터.csv', encoding='utf-8-sig', index=False)"
      ],
      "metadata": {
        "id": "Pli_r6artqN-"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_values_inf = explainer.shap_values(fe_data)\n",
        "dd = shap_values_inf[0] / np.absolute(shap_values_inf).sum()"
      ],
      "metadata": {
        "id": "uYWED5KKyHZy"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_weight = pd.DataFrame(columns = fe_data.columns)\n",
        "feature_weight.loc[0] = dd.tolist()"
      ],
      "metadata": {
        "id": "HNCaXscQrWWo"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_feature = ['지형', '공법']\n",
        "cate_main = []\n",
        "\n",
        "for i in range(len(feature_weight)) :\n",
        "  temp_1 = []\n",
        "  for name in categorical_feature : \n",
        "    temp_2 = []\n",
        "    for j in range (len(feature_weight.columns.tolist())) : \n",
        "      if name in feature_weight.columns.tolist()[j] : \n",
        "        real_name = feature_weight.columns.tolist()[j]\n",
        "        temp_2.append(feature_weight[real_name][i])\n",
        "    data_sum = np.sum(temp_2)\n",
        "    temp_1.append(data_sum)\n",
        "  cate_main.append(temp_1)"
      ],
      "metadata": {
        "id": "MyW1vPibVr1p"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ttt_f = pd.DataFrame(cate_main, columns=categorical_feature)\n",
        "\n",
        "feature_weight.drop(one_hot, axis=1, inplace=True)\n",
        "feature_weight = pd.concat([feature_weight, ttt_f], axis=1)"
      ],
      "metadata": {
        "id": "m4GPVP7dV8DD"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_weight.insert(0, '프로젝트명', pre_data['프로젝트명'].tolist())"
      ],
      "metadata": {
        "id": "US_Lh6YKbwmS"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_weight.to_csv('/content/drive/My Drive/Colab Notebooks/전인CM/output/feature_weight_물류센터.csv', encoding='utf-8-sig', index=False)"
      ],
      "metadata": {
        "id": "kvKj_xr108sp"
      },
      "execution_count": 37,
      "outputs": []
    }
  ]
}