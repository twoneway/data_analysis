{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pvSk1epGG1A",
        "outputId": "e728a6e0-e6ca-47df-b722-263d688247c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.4-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.3/70.3 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.9/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.4 yarl-1.8.2\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mysql-connector-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aURnB9F6GPKu",
        "outputId": "25330951-1801-408f-b2f3-4136c274ec76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mysql-connector-python\n",
            "  Downloading mysql_connector_python-8.0.33-cp39-cp39-manylinux1_x86_64.whl (27.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.4/27.4 MB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf<=3.20.3,>=3.11.0 in /usr/local/lib/python3.9/dist-packages (from mysql-connector-python) (3.20.3)\n",
            "Installing collected packages: mysql-connector-python\n",
            "Successfully installed mysql-connector-python-8.0.33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# package\n",
        "\n",
        "import openai\n",
        "import mysql.connector\n",
        "from pprint import pprint # chatGPT message가 잘 출력되되도록 사용\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "BZdFsiW14yxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Drive 마운트\n",
        "# 마운트는 본인 드라이브만 가능하기에 공유 폴더 같은 경우 본인 드라이브에 바로가기를 추가하여 사용\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTD2WzYG5KQx",
        "outputId": "4c719730-0489-4443-a1cb-e876199ac160"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# API KEY : contact 계정의 API key 발급하여 사용\n",
        "\n",
        "openai.api_key = \"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\""
      ],
      "metadata": {
        "id": "8eXAa6AR4jsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# google sheet를 바로 연동하는 것은 원본 훼손 위험이 존재하기에 우선 xlsx 파일을 다운로드 및 업로드하여여 활용\n",
        "\n",
        "raw_data = pd.read_excel(\"/content/drive/MyDrive/HAI 연구개발 리서치/data/PoC 평가.xlsx\", sheet_name='total')"
      ],
      "metadata": {
        "id": "0kN4airL6Y-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en_data = raw_data.copy()"
      ],
      "metadata": {
        "id": "DGFP9nY-9yhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PoC 평가가 A+인 인원들만 불러오기\n",
        "# url 주소에 userID가 존재하는 형식 데이터만 불러오기\n",
        "en_data = en_data.loc[en_data['총평 \\n(Letter grade, like A+, B+)'] == 'A+']\n",
        "en_data = en_data[en_data['framing docs'].str.contains('&userID', na = False)].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "l3W0B0WL-NLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# '&' 기준으로 파싱하여 user_id 리스트에 저장하기\n",
        "id_list = []\n",
        "for i in range(len(en_data)) :\n",
        "  id_list.append(en_data['framing docs'][i].split('&')[1][7:])"
      ],
      "metadata": {
        "id": "tXMz2ql1-aRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DB 연동\n",
        "\n",
        "mydb = mysql.connector.connect(\n",
        "  host=\"server.hyungyu.com\",\n",
        "  user=\"admin\",\n",
        "  password=\"sktmekr88!\",\n",
        "  database=\"responseDB\"\n",
        ")\n",
        "\n",
        "# 저장된 userID 정보 불러와서 사용\n",
        "userCode = id_list[1]\n",
        "\n",
        "mycursor = mydb.cursor()\n",
        "\n",
        "mycursor.execute(\"SELECT user_id from userCodeTable where code='\" + userCode + \"'\")\n",
        "\n",
        "myresult = mycursor.fetchall()\n",
        "\n",
        "userID = myresult[0][0]\n",
        "\n",
        "mycursor.execute(\"SELECT user_id, question_id, response FROM responseTable where user_id='\" + str(userID) + \"'\")\n",
        "\n",
        "myresult = mycursor.fetchall()\n",
        "\n",
        "userResponse = {}\n",
        "\n",
        "# 0부터 시작되는 문항번호를 1부터 시작하도록 변경\n",
        "for x in myresult:\n",
        "    userResponse[x[1]+1] = x[2]"
      ],
      "metadata": {
        "id": "xlOt9-8sBdSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PoC 데이터는 dictionary 형태로 저장\n",
        "userResponse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBVU4_irCI_T",
        "outputId": "9d4daef8-84e1-4461-a79a-f70e2c157de6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: 'Positive_thinking@hyundai.com',\n",
              " 2: '백승욱',\n",
              " 3: '엔진전장설계팀 / 연구원',\n",
              " 4: '엔진에 장착되는 액츄에이터류와 센서류(온도센서,압력(절대압/상대압/차압)센서,포지션센서,레벨센서,람다센서)설계를 담당하고 있습니다',\n",
              " 5: '유럽 배기규제(강화유로6) 및 중국배기규제(국6) 대응을 위해 GDI/T-GDI엔진 탑재 차종에 GPF(Gasoline Particulate Filter)라는 부품이 적용 되고(타입에 따라 UF-GPF, CC-GPF 두가지가 존재) 이에 따른 진단 및 제어를 위해 배기온도센서라는 부품이 GPF 전/후단에 추가됨.\\n\\n배기온도센서라는 부품의 개발을 위해 정확한 실제 환경온도 확인이 필요하나 실제로는 개발시 확인된 최고 온도 기준으로 개발이 됨\\n(전 차종의 온도를 검증 하는 것도 아니고, 실제 필드 운전 조건의 모든 데이터 미반영) \\n이에 배기온도센서 장착 부위의 실제 배기가스온도 예측에 M/L을 적용 하고자 함.',\n",
              " 6: '현재는 개발시 검증되는 대표 차종의 배기가스온도를 기준으로 개발하며, 개발목표 온도를 초과하는 차(개발차/양산차)가 확인 될 경우 HW조치(내열등급이 높은 부품 개발) 혹은 SW조치(출력제어, 재생제어)를 함.\\n\\n현 Heuristics 방법으로는 정확한 배기가스온도 예측이 어려워 문제 발생 가능성 존재 및 최적화가 불가하므로 고도화된 인공지능을 통한 오차율 낮은 배기가스온도 예측이 필요 \\n',\n",
              " 7: '온도센서는 아니지만 엔진에 적용되는 센서값을 모델링하는데 ML기법을 사용한 논문을 가지고 있습니다\\n(https://saemobilus.sae.org/content/2020-01-0735)\\n정확한 링크는 못찾겠습니다\\n사내 Data base에서 개인PC에 다운받아 보유하고 있으므로 필요시 전달드리겠습니다',\n",
              " 8: '회귀모델을 이용해 배기온도센서가 장착되는 부위의 배기가스온도 예측',\n",
              " 9: '1. 부품개발을 최적 화(현재 부품의 보증온도보다 높은 온도 발생 가능 시 부품에 선 반영하여 개발\\n   혹은 예상한 온도보다 낮은온도 발생 시 내열 등급이 낮은 재질을 사용하여 원가절감 가능)\\n2. ECU MAKER에 따라 예측 모델로 센서 대체 가능(모델링값이 고도화 되었을 경우 센서 츨정 값  대체 하여 진단 및 제어에 활용)\\n   현 배기온센서의 오차값은 최대구간 기준 13.5도 정도인데 동등수준 혹은 그 이상(13.5도 이하)으로 고도화 하고자 함 \\n3. 후속 차종 개발 시 출력/배출가스/연비 등을 고려한 SW변수 설정에 도움을 줄 수 있음(엔진 출력 제어, 재생제어 등)\\n4. 특정 법규대응(eg. Missing진단)을 위해 센서 실물이 꼭 필요한 경우가 아니라면 제어/진단에 이용하는 타 온도센서에도 동일한 알고리즘 적용 검토 가능',\n",
              " 10: '센서 대체(삭제)검토를 위해 현 센서 수준의 온도 예측 필요(MAE 13.5이하, COD 0.9이상)',\n",
              " 11: '수치 예측',\n",
              " 12: '배기온도센서 장착 위치의 배기가스 온도(GPF 전/후단(2point)의 온도)',\n",
              " 13: '시계열 데이터 처럼 표현\\nx축 : 시간\\ny축 : 배기온센서 실측온도 와 인공지능 예측(모델)온도 비교\\n      (그 외 차량속도, 엔진 RPM 등 간단한 차량 구동 정보(Main Feature)들도 y축에 함께 표시되어야 함)\\n\\n즉, 시간에 따라 Features를 변경 시켰을 때 실제 센서 측정 값과 인공지능 예측값(모델값)이 거의 동일함이 보이면 좋습니다 ',\n",
              " 14: '모든 개발차에 대해 배기가스 온도를 검증하고, 양산차에 대해서도 배기가스 값 모니터링.',\n",
              " 15: '0',\n",
              " 16: 'GPF 전/후단 배기가스 온도 예측',\n",
              " 17: '0',\n",
              " 18: '데이터플랫폼팀(상이할 수도 있습니다)',\n",
              " 19: '- 권한이슈 : 담당팀과 확인 필요\\n- 보안이슈 : 담당팀과 확인 필요\\n- 결제 프로세스 : 담당팀과 확인 필요\\n- 담당자 : 모름',\n",
              " 20: '연구개발정보보호팀(?)과 협의 필요',\n",
              " 21: 'LABEL이 존재함(배기온도센서의 실측 온도 값)',\n",
              " 22: '-Feature : Soot 재생 및 적산모델(Passive & Active) 관련 변수, 차량속도, 엔진PRM, 엔진부하, 엔진토크, 악셀페달센서 신호, 오일레벨, 마일리지, 냉각수온, 점화시기, 공연비, Fuel cut, CVVT제어값, 연료압, 외기온\\n-Label : GPF 전/후방 배기가스온도',\n",
              " 23: '-VCRM(Vehicle Customer Relationship Management, 차량 구동 CAN/CANFD 데이터)\\n 단, 수집 중이지 않은 차량 변수는 추가하여 수집 필요',\n",
              " 24: '-Feature : 엔진RPM, 엔진부하, 마일리지, 냉각수온\\n-Label : GPF 전/후방 배기가스온도'}"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 문항 정보 입력\n",
        "qna = pd.read_csv(\"/content/drive/MyDrive/HAI 연구개발 리서치/data/PoC_Question.csv\")"
      ],
      "metadata": {
        "id": "JjmKHv_AITd9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 초기 system role 세팅\n"
      ],
      "metadata": {
        "id": "TjOXybawGVcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BxQvyH7DDNLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = 22\n",
        "messages = [{\"role\": \"system\", \"content\": \"너는 AI 분야의 data scientist야\"},\n",
        "            {\"role\" : \"system\", \"content\" : f\"{str(qna['문항번호'][i-1])}번 문항 : {qna['문항'][i-1]}\"}\n",
        "            ]\n",
        "\n",
        "messages.append({\"role\" : \"user\", \"content\" : f\"{i}번 문항 답변 : '원재료1-유동지수/원재료1-충격강도/원재료2-유동지수/원재료2-녹는점/원재료3-인열강도/ ... 원재료n-상대점도/제품의 유동지수'\"})\n",
        "\n",
        "completion = openai.ChatCompletion.create(\n",
        "model=\"gpt-3.5-turbo\",\n",
        "messages=messages,\n",
        "temperature=1\n",
        ")\n",
        "\n",
        "chat_response = completion.choices[0].message.content\n",
        "messages.append({\"role\" : \"assistant\", \"content\" : chat_response})"
      ],
      "metadata": {
        "id": "1pSGWm3dDQUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [{\"role\": \"system\", \"content\": \"너는 AI 분야의 data scientist야\"},\n",
        "            {\"role\" : \"system\", \"content\" : f\"{str(qna['문항번호'][i-1])}번 문항 : {qna['문항'][i-1]}\"},\n",
        "            {\"role\" : \"user\", \"content\" : f\"{i}번 문항 답변 : '원재료1-유동지수/원재료1-충격강도/원재료2-유동지수/원재료2-녹는점/원재료3-인열강도/ ... 원재료n-상대점도/제품의 유동지수'\"},\n",
        "            \"role\" : \"assistant\", \"content\" : chat_response}\n",
        "            ]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jp5U0iLDuZJ",
        "outputId": "7276435d-099a-4e0e-f110-b56aa0b6c29d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'role': 'system', 'content': '너는 AI 분야의 data scientist야'},\n",
              " {'role': 'assistant',\n",
              "  'content': '22번 문항 : 인공지능을 위한 초기 데이터 세트를 설계하세요. (feature 1/ feature2 / feature3 .. feature n / label)'},\n",
              " {'role': 'user',\n",
              "  'content': \"22번 문항 답변 : '원재료1-유동지수/원재료1-충격강도/원재료2-유동지수/원재료2-녹는점/원재료3-인열강도/ ... 원재료n-상대점도/제품의 유동지수'\"},\n",
              " {'role': 'assistant',\n",
              "  'content': '위의 답변이 주어졌을 때, 해당 데이터 셋은 제품의 유동 지수를 예측하는 것으로 보입니다. 하지만, 데이터가 어떻게 수집되었는지, 어떤 방법으로 전처리되었는지 등의 정보는 전혀 없기 때문에, 추가적인 정보가 필요합니다. 또한 유동 지수를 예측하기 위해 사용된 feature들과 label 사이의 상관관계나 예측 모델의 정확도 등에 대한 정보도 필요합니다.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6개 문항 선택\n",
        "i = 5\n",
        "messages.append({\"role\" : \"assistant\", \"content\" : f\"{str(qna['문항번호'][i-1])}번 문항 : {qna['문항'][i-1]}\"})\n",
        "messages.append({\"role\" : \"user\", \"content\" : f\"{i}번 문항 답변 : {userResponse[i]}\"})\n",
        "\n",
        "completion = openai.ChatCompletion.create(\n",
        "model=\"gpt-3.5-turbo\",\n",
        "messages=messages,\n",
        "temperature=1\n",
        ")\n",
        "\n",
        "chat_response = completion.choices[0].message.content\n",
        "messages.append({\"role\" : \"assistant\", \"content\" : chat_response})"
      ],
      "metadata": {
        "id": "dyHvpbTzGWqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = 8\n",
        "messages.append({\"role\" : \"assistant\", \"content\" : f\"{str(qna['문항번호'][i-1])}번 문항 : {qna['문항'][i-1]}\"})\n",
        "messages.append({\"role\" : \"user\", \"content\" : f\"{i}번 문항 답변 : {userResponse[i]}\"})\n",
        "\n",
        "completion = openai.ChatCompletion.create(\n",
        "model=\"gpt-3.5-turbo\",\n",
        "messages=messages,\n",
        "temperature=1\n",
        ")\n",
        "\n",
        "chat_response = completion.choices[0].message.content\n",
        "messages.append({\"role\" : \"assistant\", \"content\" : chat_response})"
      ],
      "metadata": {
        "id": "JHBR3JQXLA5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = 22\n",
        "messages.append({\"role\" : \"assistant\", \"content\" : f\"{str(qna['문항번호'][i-1])}번 문항 : {qna['문항'][i-1]}\"})\n",
        "messages.append({\"role\" : \"user\", \"content\" : f\"{i}번 문항 답변 : {userResponse[i]}\"})\n",
        "\n",
        "completion = openai.ChatCompletion.create(\n",
        "model=\"gpt-3.5-turbo\",\n",
        "messages=messages,\n",
        "temperature=1\n",
        ")\n",
        "\n",
        "chat_response = completion.choices[0].message.content\n",
        "messages.append({\"role\" : \"assistant\", \"content\" : chat_response})"
      ],
      "metadata": {
        "id": "47VTrJ4ILCN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages.append({\"role\" : \"user\", \"content\" : \"위 22번에 대한 예시로 10개 row를 보유하고 있는 데이터프레임을 구성해줘\"})\n",
        "\n",
        "completion = openai.ChatCompletion.create(\n",
        "model=\"gpt-3.5-turbo\",\n",
        "messages=messages,\n",
        "temperature=1\n",
        ")\n",
        "\n",
        "chat_response = completion.choices[0].message.content\n",
        "messages.append({\"role\" : \"assistant\", \"content\" : chat_response})"
      ],
      "metadata": {
        "id": "3UM1Ao1ILynn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages.append({\"role\" : \"user\", \"content\" : \"위 구성한 데이터프레임을 활용하여 인공지능 모델 구축 코드를 만들고 해당 metrics까지 산출해줘\"})\n",
        "\n",
        "completion = openai.ChatCompletion.create(\n",
        "model=\"gpt-3.5-turbo\",\n",
        "messages=messages,\n",
        "temperature=1\n",
        ")\n",
        "\n",
        "chat_response = completion.choices[0].message.content\n",
        "messages.append({\"role\" : \"assistant\", \"content\" : chat_response})"
      ],
      "metadata": {
        "id": "DTUBanEJMIkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 초기 system role 세팅\n",
        "messages = [{\"role\": \"system\", \"content\": \"너는 AI 분야의 data scientist야\"}]"
      ],
      "metadata": {
        "id": "5SWRhs7LdrT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = 22\n",
        "messages.append({\"role\" : \"assistant\", \"content\" : f\"{str(qna['문항번호'][i-1])}번 문항 : {qna['문항'][i-1]}\"})\n",
        "messages.append({\"role\" : \"user\", \"content\" : f\"{i}번 문항 답변 : {userResponse[i]}\"})\n",
        "\n",
        "completion = openai.ChatCompletion.create(\n",
        "model=\"gpt-3.5-turbo\",\n",
        "messages=messages,\n",
        "temperature=1\n",
        ")\n",
        "\n",
        "chat_response = completion.choices[0].message.content\n",
        "messages.append({\"role\" : \"assistant\", \"content\" : chat_response})"
      ],
      "metadata": {
        "id": "iGuMAM8OdtiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages.append({\"role\" : \"user\", \"content\" : \"위 22번에 대한 예시로 10개 row를 보유하고 있는 데이터프레임을 구성해줘\"})\n",
        "\n",
        "completion = openai.ChatCompletion.create(\n",
        "model=\"gpt-3.5-turbo\",\n",
        "messages=messages,\n",
        "temperature=1\n",
        ")\n",
        "\n",
        "chat_response = completion.choices[0].message.content\n",
        "messages.append({\"role\" : \"assistant\", \"content\" : chat_response})"
      ],
      "metadata": {
        "id": "hvGFE5IqNZXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages.append({\"role\" : \"user\", \"content\" : \"위 데이터프레임을 feature 명칭, Label 명칭을 참고하여 python code로 생성한 후, csv 파일로 결과를 얻을 수 있도록 코드를 구축해줘\"})\n",
        "\n",
        "completion = openai.ChatCompletion.create(\n",
        "model=\"gpt-3.5-turbo\",\n",
        "messages=messages,\n",
        "temperature=1\n",
        ")\n",
        "\n",
        "chat_response = completion.choices[0].message.content\n",
        "messages.append({\"role\" : \"assistant\", \"content\" : chat_response})"
      ],
      "metadata": {
        "id": "S3TEe1BugCZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxZz80Ked6o7",
        "outputId": "23a06efb-2b4a-4723-e095-8281046c46f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'role': 'system', 'content': '너는 AI 분야의 data scientist야'},\n",
              " {'role': 'assistant',\n",
              "  'content': '22번 문항 : 인공지능을 위한 초기 데이터 세트를 설계하세요. (feature 1/ feature2 / feature3 .. feature n / label)'},\n",
              " {'role': 'user',\n",
              "  'content': '22번 문항 답변 : * 사외 접속환경이라 지금 생각나는 것만 우선 기록합니다.\\n\\n\\nFeature 1: 기술투자비   \\nFeature 2: 인건비 \\nFeature 3: 직접 재료비  \\nFeature 4: 간접 재료비 \\nFeature 5: 차종코드 \\nFeature 6: 차급 (고급/일반/기본 등) \\nFeature 7: 생산년도\\nFeature 8: 플랫폼 (RV,세단 등)\\nFeature 9: 연료 (전기차, 수소차, 가솔린, 디젤 등)\\nFeature 10 : 적용 옵션명 \\n\\nLabel : 옵션별 판매량 '},\n",
              " {'role': 'assistant',\n",
              "  'content': '좋은 데이터셋 설계입니다. 각 feature들은 옵션별 판매량과의 상관관계를 파악하기에 적절한 요소들이며 label도 명확하게 설정하여 모델의 학습에 활용할 수 있습니다. 특히 플랫폼과 연료 등 다양한 변수를 함께 활용하여 모델의 정확도를 높일 수 있을 것으로 보입니다.'},\n",
              " {'role': 'user', 'content': '위 22번에 대한 예시로 10개 row를 보유하고 있는 데이터프레임을 구성해줘'},\n",
              " {'role': 'assistant',\n",
              "  'content': '아래는 10개 row를 보유한 예시 데이터프레임입니다.\\n\\n| 기술투자비 | 인건비 | 직접 재료비 | 간접 재료비 | 차종코드 | 차급 | 생산년도 | 플랫폼 | 연료 | 적용 옵션명 | 옵션별 판매량 |\\n|-----------|--------|------------|------------|---------|------|---------|--------|------|-------------|-------------|\\n| 1200      | 500    | 800        | 150        | 001      | 고급  | 2020     | RV     | 전기 | 네비게이션       | 20          |\\n| 1500      | 700    | 1200       | 300        | 005      | 기본  | 2021     | 세단   | 가솔린 | 블랙박스      | 15          |\\n| 800       | 400    | 500        | 200        | 002      | 일반  | 2019     | SUV   | 디젤   | 힐드 컨트롤    | 8           |\\n| 900       | 450    | 700        | 100        | 004      | 중급  | 2018     | 세단   | 가솔린 | 네비게이션 | 18          |\\n| 1300      | 600    | 1000       | 200        | 006      | 고급  | 2021     | SUV   | 수소   | 블루투스      | 12          |\\n| 1100      | 550    | 900        | 250        | 003      | 일반  | 2020     | 기타   | 가솔린 | 네비게이션 | 22          |\\n| 1000      | 400    | 600        | 150        | 001      | 기본  | 2019     | RV     | 가솔린 | 블루투스      | 13          |\\n| 700       | 350    | 500        | 100        | 005      | 일반  | 2021     | SUV   | 전기 | 힐드 컨트롤    | 7           |\\n| 1400      | 550    | 800        | 300        | 003      | 중급  | 2018     | 세단   | 디젤   | 블랙박스      | 14          |\\n| 1200      | 500    | 900        | 200        | 006      | 고급  | 2021     | SUV   | 수소   | 힐드 컨트롤    | 16          |'},\n",
              " {'role': 'user',\n",
              "  'content': '위 데이터프레임을 feature 명칭, Label 명칭을 참고하여 python code로 생성한 후, csv 파일로 결과를 얻을 수 있도록 코드를 구축해줘'},\n",
              " {'role': 'assistant',\n",
              "  'content': '아래 코드는 위에서 제시한 예시 데이터프레임을 생성하고, 해당 데이터프레임을 CSV 파일로 저장하는 코드입니다.\\n\\n```python\\nimport pandas as pd\\n\\n# 10개의 row를 보유한 예시 데이터프레임 생성\\ndf = pd.DataFrame({\\n    \\'기술투자비\\': [1200, 1500, 800, 900, 1300, 1100, 1000, 700, 1400, 1200],\\n    \\'인건비\\': [500, 700, 400, 450, 600, 550, 400, 350, 550, 500],\\n    \\'직접 재료비\\': [800, 1200, 500, 700, 1000, 900, 600, 500, 800, 900],\\n    \\'간접 재료비\\': [150, 300, 200, 100, 200, 250, 150, 100, 300, 200],\\n    \\'차종코드\\': [\\'001\\', \\'005\\', \\'002\\', \\'004\\', \\'006\\', \\'003\\', \\'001\\', \\'005\\', \\'003\\', \\'006\\'],\\n    \\'차급\\': [\\'고급\\', \\'기본\\', \\'일반\\', \\'중급\\', \\'고급\\', \\'일반\\', \\'기본\\', \\'일반\\', \\'중급\\', \\'고급\\'],\\n    \\'생산년도\\': [2020, 2021, 2019, 2018, 2021, 2020, 2019, 2021, 2018, 2021],\\n    \\'플랫폼\\': [\\'RV\\', \\'세단\\', \\'SUV\\', \\'세단\\', \\'SUV\\', \\'기타\\', \\'RV\\', \\'SUV\\', \\'세단\\', \\'SUV\\'],\\n    \\'연료\\': [\\'전기\\', \\'가솔린\\', \\'디젤\\', \\'가솔린\\', \\'수소\\', \\'가솔린\\', \\'가솔린\\', \\'전기\\', \\'디젤\\', \\'수소\\'],\\n    \\'적용 옵션명\\': [\\'네비게이션\\', \\'블랙박스\\', \\'힐드 컨트롤\\', \\'네비게이션\\', \\'블루투스\\', \\'네비게이션\\', \\'블루투스\\', \\'힐드 컨트롤\\', \\'블랙박스\\', \\'힐드 컨트롤\\'],\\n    \\'옵션별 판매량\\': [20, 15, 8, 18, 12, 22, 13, 7, 14, 16]\\n})\\n# 데이터프레임 확인\\nprint(df)\\n\\n# 데이터프레임을 CSV 파일로 저장\\ndf.to_csv(\\'example_dataframe.csv\\', index=False)\\n```\\n\\n위 코드를 실행하면 \"example_dataframe.csv\"라는 파일이 생성되며 해당 파일을 열어보면 위 예시 데이터프레임과 같은 내용을 확인할 수 있습니다.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 일단 대충 얼기설기 짜놓았습니다.\n",
        "# 앞에서부터 탐색 / 뒤에서부터 탐색 두개로 각각 발견되면 멈추게 짜면 될 것 같습니다.\n",
        "divided = chat_response.split('\\n')\n",
        "idx = []\n",
        "for i, w in enumerate(divided):\n",
        "    if w.startswith(\"```\") or w.endswith(\"```\"):\n",
        "        idx.append(i)\n",
        "output_code = '\\n'.join(divided[idx[0]+1:idx[-1]])\n",
        "\n",
        "pprint(output_code)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5mXhRCXNyZN",
        "outputId": "8c09a3ae-14fb-486e-80bb-4f19d515413f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('import pandas as pd\\n'\n",
            " '\\n'\n",
            " '# 10개의 row를 보유한 예시 데이터프레임 생성\\n'\n",
            " 'df = pd.DataFrame({\\n'\n",
            " \"    '기술투자비': [1200, 1500, 800, 900, 1300, 1100, 1000, 700, 1400, 1200],\\n\"\n",
            " \"    '인건비': [500, 700, 400, 450, 600, 550, 400, 350, 550, 500],\\n\"\n",
            " \"    '직접 재료비': [800, 1200, 500, 700, 1000, 900, 600, 500, 800, 900],\\n\"\n",
            " \"    '간접 재료비': [150, 300, 200, 100, 200, 250, 150, 100, 300, 200],\\n\"\n",
            " \"    '차종코드': ['001', '005', '002', '004', '006', '003', '001', '005', '003', \"\n",
            " \"'006'],\\n\"\n",
            " \"    '차급': ['고급', '기본', '일반', '중급', '고급', '일반', '기본', '일반', '중급', '고급'],\\n\"\n",
            " \"    '생산년도': [2020, 2021, 2019, 2018, 2021, 2020, 2019, 2021, 2018, 2021],\\n\"\n",
            " \"    '플랫폼': ['RV', '세단', 'SUV', '세단', 'SUV', '기타', 'RV', 'SUV', '세단', \"\n",
            " \"'SUV'],\\n\"\n",
            " \"    '연료': ['전기', '가솔린', '디젤', '가솔린', '수소', '가솔린', '가솔린', '전기', '디젤', '수소'],\\n\"\n",
            " \"    '적용 옵션명': ['네비게이션', '블랙박스', '힐드 컨트롤', '네비게이션', '블루투스', '네비게이션', '블루투스', \"\n",
            " \"'힐드 컨트롤', '블랙박스', '힐드 컨트롤'],\\n\"\n",
            " \"    '옵션별 판매량': [20, 15, 8, 18, 12, 22, 13, 7, 14, 16]\\n\"\n",
            " '})\\n'\n",
            " '# 데이터프레임 확인\\n'\n",
            " 'print(df)\\n'\n",
            " '\\n'\n",
            " '# 데이터프레임을 CSV 파일로 저장\\n'\n",
            " \"df.to_csv('example_dataframe.csv', index=False)\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/HAI 연구개발 리서치/output/output_script_2.py', 'w') as f:\n",
        "    f.write(output_code)"
      ],
      "metadata": {
        "id": "Jy540N-jeCRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Code_CoT_test(q_1:str, q_2:str, q_3:str, plot:list, ChatGPT_api_key:str, data_path:str, model:str=\"gpt-3.5-turbo\")->str:\n",
        "\n",
        "    openai.api_key = ChatGPT_api_key\n",
        "\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"인공지능 모델을 활용하여 개선이 가능한 영역인지 확인해줘\",\n",
        "        },\n",
        "\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"인공지능을 활용했을 때, 회귀, 분류 모델 중 어떤 모델이 적합한지 확인해줘\",\n",
        "        },\n",
        "\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"개선이 필요한 영역을 한 줄로 정리해서 요약해줘\",\n",
        "        },\n",
        "\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f'인공지능을 적용하여여 개선이 필요한 영역은 \"{q_1}\"이야'\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    response = openai.ChatCompletion.create(model=model, messages=messages)\n",
        "\n",
        "    answer_1 = response[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": f\"'{answer_1}' 영역에 대해 인공지능을 활용하고 싶어\",\n",
        "        },\n",
        "\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"인공지능이 예측하려는 Target이 무엇인지 확인해줘\",\n",
        "        },\n",
        "\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"인공지능의 목적을 한 줄로 정리해서 요약해줘.\",\n",
        "        },\n",
        "\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f'인공지능의 목적은 \"{q_2}\"이야'\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    response = openai.ChatCompletion.create(model=model, messages=messages)\n",
        "    answer_2 = response[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": f\"AI의 주제는 '{answer_2}'이야\",\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"입력된 데이터를 feature와 label 두 종류로 구분해줘\",\n",
        "        },\n",
        "\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\":\"python script를 사용하여 dataframe을 생성해줘\",\n",
        "        },\n",
        "\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"결과 전달 시 python script만 출력해줘\",\n",
        "        },\n",
        "\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"dataframe 생성 시, column의 명칭은 입력된 feature와 Label 명칭으로 사용해줘\",\n",
        "        },\n",
        "\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"dataframe의 value값들은 임의로 10개만 생성해줘\",\n",
        "        },\n",
        "\n",
        "         {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": f\"생성한 dataframe의 저장 경로는 {data_path}야\",\n",
        "        },\n",
        "\n",
        "         {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"위 단계들을 차근차근 생각해줘\",\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"예시 데이터 세트는 '{q_3}'이야. dataframe을 생성하고 저장해줘\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    response = openai.ChatCompletion.create(model=model, messages=messages)\n",
        "    answer_3 = response[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "    messages = [\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": f\"인공지능의 목적은 '{answer_2}'이야\",\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": f\"현재 보유한 데이터프레임은 {answer_3}이야\",\n",
        "            },\n",
        "\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"AI Modeling 관점으로 사용가능한 plot들을 1개만 추천해줘\",\n",
        "            },\n",
        "\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\":\"데이터프레임의 feature들을 참고하여 사용가능한 plot들을 1개만 추천해줘\",\n",
        "            },\n",
        "\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": f\"plot들을 추천할 시 {plot} 리스트 목록에 존재하는 plot들만 추천해줘\",\n",
        "            },\n",
        "\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": '데이터프레임을 참고하여 필요한 시각화 plot들을 추천해줘'\n",
        "            }\n",
        "        ]\n",
        "\n",
        "    response = openai.ChatCompletion.create(model=model, messages=messages)\n",
        "    answer_4 = response[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "    return answer_3, answer_4\n",
        "'''\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": f\"지금부터 {answer_3}를 리뷰할거야\",\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"차근차근 생각하고 효율적으로 코드를 구축해줘\",\n",
        "        },\n",
        "\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"결과 전달 시 python script만 출력해줘\",\n",
        "        },\n",
        "\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\":f\"생성한 {answer_3}가 실행하는데 문제가 없는지 체크해줘\",\n",
        "        },\n",
        "\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": f\"실행하는데 문제가 발생하지 않을 경우 {answer_3}를 그대로 둬\",\n",
        "        },\n",
        "\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f'생성한 {answer_3}를 리뷰해주고 python script를 다시 전달해줘'\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    response = openai.ChatCompletion.create(model=model, messages=messages)\n",
        "    answer_3 = response[\"choices\"][0][\"message\"][\"content\"]\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "6F7gqw3aO_J4",
        "outputId": "2998c075-b54b-4d64-b1ec-808d5cc48420"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n    messages = [\\n        {\\n            \"role\": \"system\",\\n            \"content\": f\"지금부터 {answer_3}를 리뷰할거야\",\\n        },\\n        {\\n            \"role\": \"system\",\\n            \"content\": \"차근차근 생각하고 효율적으로 코드를 구축해줘\",\\n        },\\n        \\n        {\\n            \"role\": \"system\",\\n            \"content\": \"결과 전달 시 python script만 출력해줘\",\\n        },\\n\\n        {\\n            \"role\": \"system\",\\n            \"content\":f\"생성한 {answer_3}가 실행하는데 문제가 없는지 체크해줘\",\\n        },\\n    \\n        {\\n            \"role\": \"system\",\\n            \"content\": f\"실행하는데 문제가 발생하지 않을 경우 {answer_3}를 그대로 둬\",\\n        },\\n\\n        {\\n            \"role\": \"user\", \\n            \"content\": f\\'생성한 {answer_3}를 리뷰해주고 python script를 다시 전달해줘\\'\\n        }\\n    ]\\n\\n    response = openai.ChatCompletion.create(model=model, messages=messages)\\n    answer_3 = response[\"choices\"][0][\"message\"][\"content\"]\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output, output_2 = Code_CoT_test(q_1=userResponse[5], q_2=userResponse[8], q_3=userResponse[22],\n",
        "                      plot = [\"feature_importance\", \"roc_curve\", \"bar_plot\", \"line_plot\", \"pie_plot\", \"heatmap\", \"confusion_matrix\", \"histogram\"],\n",
        "                      ChatGPT_api_key=openai.api_key,\n",
        "                      data_path='/content/drive/MyDrive/HAI 연구개발 리서치/output/',\n",
        "                      model=\"gpt-3.5-turbo\")"
      ],
      "metadata": {
        "id": "Yr60QXOZSRkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint"
      ],
      "metadata": {
        "id": "7Wf3EQ4nTttV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yN5TsxVjT9rn",
        "outputId": "4bf09784-62f1-4c95-8c31-ddb9b224edc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('데이터프레임을 생성 및 저장하는 코드는 다음과 같습니다.\\n'\n",
            " '\\n'\n",
            " '```\\n'\n",
            " 'import pandas as pd\\n'\n",
            " 'import numpy as np\\n'\n",
            " '\\n'\n",
            " '# Feature와 Label 데이터\\n'\n",
            " \"features = ['Soot_regen_Passive', 'Soot_regen_Active', 'vehicle_speed', \"\n",
            " \"'engine_RPM', 'engine_load', 'engine_torque',\\n\"\n",
            " \"            'accel_pedal_signal', 'oil_level', 'mileage', \"\n",
            " \"'coolant_temperature', 'ignition_timing', 'afr', 'fuel_cut',\\n\"\n",
            " \"            'cvvt_control', 'fuel_pressure', 'ambient_temperature']\\n\"\n",
            " \"label = 'GPF_bef/aft_gas_temp'\\n\"\n",
            " '\\n'\n",
            " '# 임의의 값 생성\\n'\n",
            " 'data = dict(zip(features, np.random.randn(10, len(features)).tolist()))\\n'\n",
            " 'data[label] = np.random.randn(10)\\n'\n",
            " '\\n'\n",
            " '# 데이터프레임 생성\\n'\n",
            " 'df = pd.DataFrame(data=data, columns=features + [label])\\n'\n",
            " '\\n'\n",
            " '# 저장\\n'\n",
            " \"path = '/content/drive/MyDrive/HAI 연구개발 개발업무/output/'\\n\"\n",
            " \"df.to_csv(path + 'data.csv', index=False)\\n\"\n",
            " '```\\n'\n",
            " '위 코드를 실행하면 /content/drive/MyDrive/HAI 연구개발 개발업무/output/ 폴더 내부에 data.csv 파일이 '\n",
            " '생성됩니다. ')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(output_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvaPGU3XfLoE",
        "outputId": "f949f2d7-b1ff-4e70-9f20-4bad6978a361"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "주어진 feature들을 다양한 방식으로 시각화 할 수 있지만, 가장 일반적으로 사용되는 시각화 기법 중 몇 가지를 추천해 드릴게요.\n",
            "\n",
            "1. Histogram - 주어진 데이터가 어떤 분포를 따르는지 시각적으로 확인할 수 있습니다. feature 중 continuous variable이 있는 경우 유용한 시각화 기법입니다.\n",
            "\n",
            "2. Line Plot - 시간에 따라 변화를 보여주는 feature들의 경우, Line Plot을 사용하여 시계열 데이터를 시각화할 수 있습니다.\n",
            "\n",
            "3. Bar Plot - 범주형 변수에 대한 count 정보를 시각화하는 데 매우 유용한 plot입니다.\n",
            "\n",
            "4. Heatmap - Correlation Matrix를 시각화하여 변수 간의 상관 관계를 확인하는 데 사용됩니다.\n",
            "\n",
            "여기서 해당 feature들 중 continuous variable을 가진 데이터를 시각화하고자 한다면 Histogram 또는 KDE plot이 적합합니다. 또한, feature간의 관계를 시각화하고자 할 경우, Pairplot이나 Scatter plot도 사용할 수 있습니다. 이 중에서는 Histogram과 Heatmap이 가장 유용한 plot들 중 하나이기 때문에, 추천해드릴 plot은 다음과 같습니다.\n",
            "\n",
            "1. Histogram (feature 중 continuous variable을 가진 경우)\n",
            "2. Heatmap (feature간의 상관 관계를 확인하고자 할 때)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 일단 대충 얼기설기 짜놓았습니다.\n",
        "# 앞에서부터 탐색 / 뒤에서부터 탐색 두개로 각각 발견되면 멈추게 짜면 될 것 같습니다.\n",
        "divided = output.split('\\n')\n",
        "idx = []\n",
        "for i, w in enumerate(divided):\n",
        "    if w.startswith(\"```\") or w.endswith(\"```\"):\n",
        "        idx.append(i)\n",
        "output_code = '\\n'.join(divided[idx[0]+1:idx[1]])\n",
        "\n",
        "pprint(output_code)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34DG6VM1T_DM",
        "outputId": "226e0553-f702-41df-c5e6-680e927358dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('import pandas as pd\\n'\n",
            " 'import numpy as np\\n'\n",
            " '\\n'\n",
            " '# Feature와 Label 데이터\\n'\n",
            " \"features = ['Soot_regen_Passive', 'Soot_regen_Active', 'vehicle_speed', \"\n",
            " \"'engine_RPM', 'engine_load', 'engine_torque',\\n\"\n",
            " \"            'accel_pedal_signal', 'oil_level', 'mileage', \"\n",
            " \"'coolant_temperature', 'ignition_timing', 'afr', 'fuel_cut',\\n\"\n",
            " \"            'cvvt_control', 'fuel_pressure', 'ambient_temperature']\\n\"\n",
            " \"label = 'GPF_bef/aft_gas_temp'\\n\"\n",
            " '\\n'\n",
            " '# 임의의 값 생성\\n'\n",
            " 'data = dict(zip(features, np.random.randn(10, len(features)).tolist()))\\n'\n",
            " 'data[label] = np.random.randn(10)\\n'\n",
            " '\\n'\n",
            " '# 데이터프레임 생성\\n'\n",
            " 'df = pd.DataFrame(data=data, columns=features + [label])\\n'\n",
            " '\\n'\n",
            " '# 저장\\n'\n",
            " \"path = '/content/drive/MyDrive/HAI 연구개발 개발업무/output/'\\n\"\n",
            " \"df.to_csv(path + 'data.csv', index=False)\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/HAI 연구개발 리서치/output/output_poc_3.py', 'w') as f:\n",
        "    f.write(output_code)"
      ],
      "metadata": {
        "id": "lRhU11cgUAwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%run -i '/content/drive/MyDrive/HAI 연구개발 리서치/output/output_poc_2.py'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "v0TP_6vCYGbi",
        "outputId": "a903156f-7c26-4721-a340-a585bcd9d3e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/content/drive/MyDrive/HAI 연구개발 리서치/output/output_poc_2.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# DataFrame 저장\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0moutput_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/HAI 연구개발 강의 자료/output/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'야나두_옵션별_판매량.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3718\u001b[0m         )\n\u001b[1;32m   3719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3720\u001b[0;31m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[1;32m   3721\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3722\u001b[0m             \u001b[0mlineterminator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlineterminator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1187\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m         )\n\u001b[0;32m-> 1189\u001b[0;31m         \u001b[0mcsv_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \"\"\"\n\u001b[1;32m    240\u001b[0m         \u001b[0;31m# apply compression and byte/text conversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         with get_handle(\n\u001b[0m\u001b[1;32m    242\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    732\u001b[0m     \u001b[0;31m# Only for write methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"r\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m         \u001b[0mcheck_parent_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    595\u001b[0m     \u001b[0mparent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mrf\"Cannot save file into a non-existent directory: '{parent}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: '/content/drive/MyDrive/HAI 연구개발 강의 자료/output'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"system : 인공지능 모델을 활용하여 개선이 가능한 영역인지 확인해줘\"\n",
        "\n",
        "\"system : 인공지능을 활용했을 때, 회귀, 분류 모델 중 어떤 모델이 적합한지 확인해줘\"\n",
        "\n",
        "\"system : 개선이 필요한 영역을 한 줄로 정리해서 요약해줘\"\n",
        "\n",
        "\"user : 인공지능을 적용하여여 개선이 필요한 영역은 {input}이야\"\n",
        "===============\n",
        "\n",
        "\"system : {요약} 영역에 대해 인공지능을 활용하고 싶어\"\n",
        "\n",
        "\"system : 인공지능이 예측하려는 Target이 무엇인지 확인해줘\"\n",
        "\n",
        "\"system : 인공지능의 목적을 한 줄로 정리해서 요약해줘\"\n",
        "\n",
        "\"user : 인공지능의 목적은 {input}이야\"\n",
        "\n",
        "=============\n",
        "\n",
        "\"AI의 주제는 {요약}이야\"\n",
        "\n",
        "\"입력된 데이터를 feature와 label 두 종류로 구분해줘\"\n",
        "\n",
        "\"python script를 사용하여 dataframe을 생성해줘\"\n",
        "\n",
        "\"dataframe 생성 시, column의 명칭은 입력된 feature와 Label 명칭으로 사용해줘\"\n",
        "\n",
        "\"dataframe의 value값들은 랜덤으로 50개만 생성해줘\"\n",
        "\n",
        "\"value 값 생성 시, feature의 type에 맞게 생성해줘\"\n",
        "\n",
        "\"생성한 데이터프레임을 csv 파일로 저장해줘\"\n",
        "\n",
        "\"생성한 dataframe의 저장 경로는 /ml/algorithmlabs.csv 폴더야\"\n",
        "\n",
        "\"저장하는 데이터의 이름은 'test_csv'야\"\n",
        "\n",
        "\"위 단계들을 차근차근 생각해줘\"\n",
        "\n",
        "\"user : 예시 데이터 세트는 {input}이야. dataframe을 생성하고 저장해줘\"\n",
        "\n",
        "# review\n",
        "\n",
        "\"지금부터 python code를 리뷰할거야\"\n",
        "\n",
        "\"차근차근 생각하고 효율적으로 코드를 구축해줘\"\n",
        "\n",
        "\"생성한 python code가 실행하는데 문제가 없는지 체크해줘\"\n",
        "\n",
        "\"실행하는데 문제가 발생하지 않을 경우 python script를 그대로 둬\"\n",
        "\n",
        "\"실행하는데 문제가 발생할 경우 python script 코드를 수정해줘\"\n",
        "\n",
        "\"user : 생성한 {answer}를 리뷰해주고 python script를 다시 전달해줘\"\n",
        "\n",
        "=================================\n",
        "\n",
        "\"개선이 필요한 프로세스는 {요약1}이야\"\n",
        "\n",
        "\"인공지능의 목적은 {요약2}이야\"\n",
        "\n",
        "\"현재 보유한 데이터프레임은 {python script}이야\"\n",
        "\n",
        "\"생성한 데이터프레임이 인공지능 회귀, 분류 모델 중 무엇이 적합한지 생각해줘\"\n",
        "\n",
        "\"인공지능 회귀 모델이 적합할 경우 사용가능한 plot들을 3개만 나열해줘\"\n",
        "\n",
        "\"인공지능 분류 모델이 적합할 경우 사용가능한 plot들을 3개만 나열해줘\"\n",
        "\n",
        "\"데이터프레임의 feature type들을 참고하여 사용할 수 있는 plot들을 3개만 나열해줘\"\n",
        "\n",
        "\"plot들을 나열할 시 반드시 {visualize plot}에 있는 plot들만 추천해줘\"\n",
        "\n",
        "\"user : 데이터프레임을 참고하여 인공지능 모델에 필요한 시각화 plot들을 알려줘\"\n",
        "\n",
        "# review\n",
        "\n",
        "\"{plot}들에 대해 리뷰할게\"\n",
        "\n",
        "\"{plot}이 {visualize plot} 목록 내에 모두 존재하면 그대로 결과를 나열해줘\"\n",
        "\n",
        "\" 만약 목록 내에 존재하지 않는다면 {visualize plot}을 기반으로 다시 나열해줘\"\n",
        "\n",
        "\"현재 보유한 데이터프레임은 {python script}이야\"\n",
        "\n",
        "\"생성한 데이터프레임이 인공지능 회귀, 분류 모델 중 무엇이 적합한지 생각해줘\"\n",
        "\n",
        "\"인공지능 회귀 모델이 적합할 경우 사용가능한 plot들을 3개만 나열해줘\"\n",
        "\n",
        "\"인공지능 분류 모델이 적합할 경우 사용가능한 plot들을 3개만 나열해줘\"\n",
        "\n",
        "\"데이터프레임의 feature type들을 참고하여 사용할 수 있는 plot들을 3개만 나열해줘\"\n",
        "\n",
        "\"plot들을 나열할 시 반드시 {visualize plot}에 있는 plot들만 추천해줘\"\n",
        "\n",
        "\"user : 데이터프레임을 참고하여 인공지능 모델에 필요한 시각화 plot들을 알려줘\""
      ],
      "metadata": {
        "id": "UgIaV6SWD9zs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}